{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmkgPGu4YaA0"
      },
      "source": [
        "## Contexto\n",
        "\n",
        "El discurso de odio es cualquier expresi贸n que promueva o incite a la discriminaci贸n, la hostilidad o la violencia hacia una persona o grupo de personas en una relaci贸n asim茅trica de poder, tal como la raza, la etnia, el g茅nero, la orientaci贸n sexual, la religi贸n, la nacionalidad, una discapacidad u otra caracter铆stica similar.\n",
        "\n",
        "En cambio, la incivilidad se refiere a cualquier comportamiento o actitud que rompe las normas de respeto, cortes铆a y consideraci贸n en la interacci贸n entre personas. Esta puede manifestarse de diversas formas, tal como insultos, ataques personales, sarcasmo, desprecio, entre otras.\n",
        "\n",
        "En esta tarea tendr谩n a su disposici贸n un dataset de textos con las etiquetas `odio`, `incivilidad` o `normal`. La mayor parte de los datos se encuentra en espa帽ol de Chile. Con estos datos, deber谩n entrenar un modelo que sea capaz de predecir la etiqueta de un texto dado.\n",
        "\n",
        "El corpus para esta tarea se compone de 3 datasets:  \n",
        "- [Multilingual Resources for Offensive Language Detection de Arango et al. (2022)](https://aclanthology.org/2022.woah-1.pdf#page=136)\n",
        "- [Dataton UTFSM No To Hate (2022)](http://dataton.inf.utfsm.cl/)\n",
        "- Datos generados usando la [API de GPT3 (modelo DaVinci 03)](https://platform.openai.com/docs/models/gpt-3).\n",
        "\n",
        "Agradecimientos a los autores por compartir los datos y a David Miranda, Fabi谩n Diaz, Santiago Maass y Jorge Ortiz por revisar y reetiquetar los datos en el contexto del curso \"Taller de Desarrollo de Proyectos de IA\" (CC6409), Departamento de Ciencias de la Computaci贸n, Universidad de Chile.\n",
        "\n",
        "Los datos solo pueden ser usados con fines de investigaci贸n y docencia. Est谩 prohibida la difusi贸n externa.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_80t9I-qYaA2"
      },
      "source": [
        "## Tarea a resolver\n",
        "\n",
        "Para esta tarea 2, buscaremos desarrollar un *benchmark* sobre una tarea de clasificaci贸n de NLP. Un benchmark es b谩sicamente utilizar diferentes t茅cnicas para resolver una misma tarea espec铆fica, en este caso seguiremos buscando alternativas para resolver el problema de clasificaci贸n de la tarea 1. Particularmente, se le pide:\n",
        "\n",
        "- Implementar una arquitectura en RNN utilizando PyTorch.\n",
        "- Utilizar transformers para revolver el problema de clasificaci贸n, en especifico utilizar BETO.\n",
        "- Utilizar alg煤n LLM utilizando Zero y Few short learning para resolver el problema de clasificaci贸n.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FMq5cAHYaA2"
      },
      "source": [
        "### Cargar el dataset\n",
        "\n",
        "\n",
        "En esta secci贸n, cargaremos el dataset desde el repositorio del m贸dulo. Para ello ejecute las siguientes l铆neas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xuRRonUXYaA3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDl3c9BKYaA5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QZMwxb4zYaA6"
      },
      "outputs": [],
      "source": [
        "# Dataset.\n",
        "dataset_df = pd.read_csv(\"https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/new/assignment_1/train/train.tsv\", sep=\"\\t\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nmaG5k2YaA6"
      },
      "source": [
        "### Analizar los datos\n",
        "\n",
        "En esta secci贸n analizaremos el balance de los datos. Para ello se imprime la cantidad de tweets de cada dataset agrupados por la intensidad de sentimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pDsF7qXUYaA8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "2d204d5a-1a50-4027-b483-b759d075ee77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id                                              texto        clase\n",
              "4504   12151  @user @user @user @user @user Mapuche piojoso ...         odio\n",
              "3683   12604  Vieja qlia maricona la del registro civil, la ...         odio\n",
              "1292     772  No son dignas de respeto, amor o afecto. Deber...         odio\n",
              "11026   8845  @user @user De verdad este CTM esta descontrol...  incivilidad\n",
              "10313  14571  Separadas al nacer ....    #RechazoGanaEl4deSe...       normal\n",
              "1227   12804  De donde sac贸 8 mil pesos para ma帽ana???? cold...  incivilidad\n",
              "7741   10491  Simplemente yo nunca entender茅 a las mujeres し...         odio\n",
              "3856    2995  @user Los dientes, si tiene zarro y dientes ne...       normal\n",
              "8039    9158  actualizacion qlia bkn hermano nunca me entret...  incivilidad\n",
              "4725   11240  @user Esta el enojado el mapuche de mierda, es...         odio\n",
              "4650    9574  #24Tarde \\n \\nUn delincuente muri贸 baleado por...  incivilidad\n",
              "7813     610  Est谩n obligando a la gente a aceptar sus desvi...         odio\n",
              "1497   10982  Es parte de los servicios que ofrece el aeropu...       normal\n",
              "1488    9945  @user Por Perroshit, Pi帽era, los pacos, kkst, ...  incivilidad\n",
              "5438    4829  Es s煤per obtuso decir que la soa Oliva perdi贸 ...  incivilidad\n",
              "4697   10305  @user @user Dudo que tu ex mujer le diga como ...         odio\n",
              "1993    6886  @user @user @user Cu谩ntas medallas ol铆mpicas t...       normal\n",
              "11454   5427  A esto me refiero \\nO esos que se pusieron...  incivilidad\n",
              "5123   14119  Habr谩 una jornada de intercambio de figuritas ...  incivilidad\n",
              "3860    7252  @user Santiago de Chile/Militantes y chilenos ...       normal"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-458d4a5f-2955-4765-afbb-765bc88fa606\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>texto</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4504</th>\n",
              "      <td>12151</td>\n",
              "      <td>@user @user @user @user @user Mapuche piojoso ...</td>\n",
              "      <td>odio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3683</th>\n",
              "      <td>12604</td>\n",
              "      <td>Vieja qlia maricona la del registro civil, la ...</td>\n",
              "      <td>odio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1292</th>\n",
              "      <td>772</td>\n",
              "      <td>No son dignas de respeto, amor o afecto. Deber...</td>\n",
              "      <td>odio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11026</th>\n",
              "      <td>8845</td>\n",
              "      <td>@user @user De verdad este CTM esta descontrol...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10313</th>\n",
              "      <td>14571</td>\n",
              "      <td>Separadas al nacer ....    #RechazoGanaEl4deSe...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1227</th>\n",
              "      <td>12804</td>\n",
              "      <td>De donde sac贸 8 mil pesos para ma帽ana???? cold...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7741</th>\n",
              "      <td>10491</td>\n",
              "      <td>Simplemente yo nunca entender茅 a las mujeres し...</td>\n",
              "      <td>odio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3856</th>\n",
              "      <td>2995</td>\n",
              "      <td>@user Los dientes, si tiene zarro y dientes ne...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8039</th>\n",
              "      <td>9158</td>\n",
              "      <td>actualizacion qlia bkn hermano nunca me entret...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4725</th>\n",
              "      <td>11240</td>\n",
              "      <td>@user Esta el enojado el mapuche de mierda, es...</td>\n",
              "      <td>odio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4650</th>\n",
              "      <td>9574</td>\n",
              "      <td>#24Tarde \\n \\nUn delincuente muri贸 baleado por...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7813</th>\n",
              "      <td>610</td>\n",
              "      <td>Est谩n obligando a la gente a aceptar sus desvi...</td>\n",
              "      <td>odio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>10982</td>\n",
              "      <td>Es parte de los servicios que ofrece el aeropu...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1488</th>\n",
              "      <td>9945</td>\n",
              "      <td>@user Por Perroshit, Pi帽era, los pacos, kkst, ...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5438</th>\n",
              "      <td>4829</td>\n",
              "      <td>Es s煤per obtuso decir que la soa Oliva perdi贸 ...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4697</th>\n",
              "      <td>10305</td>\n",
              "      <td>@user @user Dudo que tu ex mujer le diga como ...</td>\n",
              "      <td>odio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993</th>\n",
              "      <td>6886</td>\n",
              "      <td>@user @user @user Cu谩ntas medallas ol铆mpicas t...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11454</th>\n",
              "      <td>5427</td>\n",
              "      <td>A esto me refiero \\nO esos que se pusieron...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5123</th>\n",
              "      <td>14119</td>\n",
              "      <td>Habr谩 una jornada de intercambio de figuritas ...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3860</th>\n",
              "      <td>7252</td>\n",
              "      <td>@user Santiago de Chile/Militantes y chilenos ...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-458d4a5f-2955-4765-afbb-765bc88fa606')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-458d4a5f-2955-4765-afbb-765bc88fa606 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-458d4a5f-2955-4765-afbb-765bc88fa606');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6b73645f-9ec1-4269-8ca0-e385fb022cc3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6b73645f-9ec1-4269-8ca0-e385fb022cc3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6b73645f-9ec1-4269-8ca0-e385fb022cc3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset_df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4101,\n        \"min\": 610,\n        \"max\": 14571,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          12151,\n          5427,\n          10305\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"texto\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"@user @user @user @user @user Mapuche piojoso Mapuche piojoso Mapuche piojoso Mapuche piojoso, anda a ba\\u00f1arte asqueroso\",\n          \"A esto me refiero \\ud83d\\ude02\\ud83d\\ude02\\ud83d\\ude02\\ud83d\\ude02\\nO esos que se pusieron de moda ya finalizando la era MSN y se top\\u00f3 con la era de los emos\\n\\nCc\\u00a2hi\\u00ef\\u00ee\\u00eckK\\u00ef\\u00ef\\u00eet\\u00a5a\\u00e6\\u00e5\\u00e4 y bla bla\\nMe demore siglos en escribir CTM \\ud83d\\ude02\\ud83d\\ude02\\ud83d\\ude02 https://t.co/dawYJhPqxi\",\n          \"@user @user Dudo que tu ex mujer le diga como culear a tu nueva mujer, lo m\\u00e1s probable es que le diga que no sabes culear y que por eso te dej\\u00f3 \\ud83e\\udd23\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clase\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"odio\",\n          \"incivilidad\",\n          \"normal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "dataset_df.sample(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BbtCh-wrYaA9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "6b631d6d-526b-4816-d99e-4652214123d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "clase\n",
              "incivilidad    5424\n",
              "normal         4280\n",
              "odio           2510\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clase</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>incivilidad</th>\n",
              "      <td>5424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>normal</th>\n",
              "      <td>4280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>odio</th>\n",
              "      <td>2510</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "dataset_df[\"clase\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9MuLDqCr4ufP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd14157-fefd-4972-f591-48fa8b1bfe87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['normal', 'incivilidad', 'odio']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "target_classes = list(dataset_df['clase'].unique())\n",
        "target_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgIGp4p0YaA-"
      },
      "source": [
        "### Instalar librerias\n",
        "\n",
        "Puede usar esta celda para instalar las librer铆as que estime necesario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3F-Dyck6YaA_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install word2vec gensim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df7poQdIYaBA"
      },
      "source": [
        "### Importar librer铆as\n",
        "\n",
        "En esta secci贸n, importamos la liber铆as necesarias para el correcto desarrollo de esta tarea. Puede utilizar otras librer铆as que no se en encuentran aqu铆, pero debe citar su fuente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ozNxw2TD9rVX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c85cab98-88ef-4490-cc4e-f71e40c7de8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.8.0+cu126\n",
            "Uninstalling torch-2.8.0+cu126:\n",
            "  Would remove:\n",
            "    /usr/local/bin/torchfrtrace\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.12/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.12/dist-packages/torch-2.8.0+cu126.dist-info/*\n",
            "    /usr/local/lib/python3.12/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.12/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled torch-2.8.0+cu126\n",
            "Found existing installation: torchvision 0.23.0+cu126\n",
            "Uninstalling torchvision-0.23.0+cu126:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.12/dist-packages/torchvision-0.23.0+cu126.dist-info/*\n",
            "    /usr/local/lib/python3.12/dist-packages/torchvision.libs/libcudart.45e7f3ed.so.12\n",
            "    /usr/local/lib/python3.12/dist-packages/torchvision.libs/libjpeg.bd6b9199.so.8\n",
            "    /usr/local/lib/python3.12/dist-packages/torchvision.libs/libnvjpeg.e5f20359.so.12\n",
            "    /usr/local/lib/python3.12/dist-packages/torchvision.libs/libpng16.0481ee11.so.16\n",
            "    /usr/local/lib/python3.12/dist-packages/torchvision.libs/libsharpyuv.b609dd4c.so.0\n",
            "    /usr/local/lib/python3.12/dist-packages/torchvision.libs/libwebp.58a855fe.so.7\n",
            "    /usr/local/lib/python3.12/dist-packages/torchvision.libs/libz.622bbd06.so.1\n",
            "    /usr/local/lib/python3.12/dist-packages/torchvision/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled torchvision-0.23.0+cu126\n",
            "Found existing installation: torchaudio 2.8.0+cu126\n",
            "Uninstalling torchaudio-2.8.0+cu126:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.12/dist-packages/torchaudio-2.8.0+cu126.dist-info/*\n",
            "    /usr/local/lib/python3.12/dist-packages/torchaudio/*\n",
            "    /usr/local/lib/python3.12/dist-packages/torio/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Collecting torch==2.3.0\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.3.0%2Bcpu-cp312-cp312-linux_x86_64.whl (190.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m190.4/190.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (2025.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "timm 1.0.22 requires torchvision, which is not installed.\n",
            "fastai 2.8.5 requires torchvision>=0.11, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.3.0+cpu\n",
            "Found existing installation: scipy 1.16.3\n",
            "Uninstalling scipy-1.16.3:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.12/dist-packages/scipy-1.16.3.dist-info/*\n",
            "    /usr/local/lib/python3.12/dist-packages/scipy.libs/libgfortran-040039e1-0352e75f.so.5.0.0\n",
            "    /usr/local/lib/python3.12/dist-packages/scipy.libs/libgfortran-040039e1.so.5.0.0\n",
            "    /usr/local/lib/python3.12/dist-packages/scipy.libs/libquadmath-96973f99-934c22de.so.0.0.0\n",
            "    /usr/local/lib/python3.12/dist-packages/scipy.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.12/dist-packages/scipy.libs/libscipy_openblas-b75cc656.so\n",
            "    /usr/local/lib/python3.12/dist-packages/scipy/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled scipy-1.16.3\n",
            "Collecting scipy==1.11.4\n",
            "  Downloading scipy-1.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy<1.28.0,>=1.21.6 (from scipy==1.11.4)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.8 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m35.8/35.8 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.8.5 requires torchvision>=0.11, which is not installed.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires scipy>=1.13, but you have scipy 1.11.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires scipy>=1.13, but you have scipy 1.11.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 scipy-1.11.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "d03f58241d144f9db335c93fab6b85ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.32.4)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.3.0+cpu)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (2025.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (2025.10.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch>=2.3.0->torchtext) (1.3.0)\n",
            "Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u001b[0m\u001b[91m\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.18.0\n",
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from scikit-plot) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.12/dist-packages (from scikit-plot) (1.6.1)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.12/dist-packages (from scikit-plot) (1.11.4)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.12/dist-packages (from scikit-plot) (1.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.9.0.post0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.17.0)\n",
            "Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip uninstall torch torchvision torchaudio\n",
        "\n",
        "!pip install torch==2.3.0 --index-url https://download.pytorch.org/whl/cpu\n",
        "!pip uninstall scipy\n",
        "!pip install scipy==1.11.4\n",
        "!pip install torchtext\n",
        "!pip install scikit-plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MUMOdsGfYaBA"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "from nltk import word_tokenize\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# importe aqu铆 sus clasificadores\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# word2vec\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "\n",
        "# Pytorch imports\n",
        "import torch\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "\n",
        "from torch.optim import Adam\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTtn4JeJYaBD"
      },
      "source": [
        "### Crear un clasificador basado en RNN\n",
        "\n",
        "En esta parte de le pide definir un clasificador utilizando `PyTorch` con alguna arquitectura en Redes Recurrentes. Para ello debe realizar todos los pasos vistos en el tutorial 5, por lo que se recomienda revisarlo. Importante, no puede replicar ning煤n ejemplo de los del tutorial 5, debe proponer sus propias arquitecturas. Se le recomienda leer como utilizar variaciones de la RNN, como la LSTM o GRU en `Pytorch`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98nYKQJmYaBE"
      },
      "source": [
        "Para completa esta parte deber谩 replicar el flujo de trabajo de como utilizar `PyTorch`. Esta esctrictamente prohibido utilizar variaciones que resuelvan directamente este problema, como `PyTorch Lightning` o `TensorFlow`. Los pasos a completar son los siguientes:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T2bU7xgYaBE"
      },
      "source": [
        "#### Cargar el dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LVVjNAV4YaBE"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_df(df, test_size = 0.2, seed: int = 42):\n",
        "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=seed, stratify=df['clase'])\n",
        "    return train_df, test_df\n",
        "\n",
        "\n",
        "def load_df(df):\n",
        "   for _, row in df.iterrows():\n",
        "     yield row['texto'], row['clase']\n",
        "\n",
        "\n",
        "train_df, test_df = split_df(dataset_df)\n",
        "\n",
        "train_dataset = load_df(train_df)\n",
        "test_dataset = load_df(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8Zu0U4XYaBE"
      },
      "source": [
        "#### Definir el vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TY_Cgtx9YaBF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "e4b49033-75a3-4094-c0b4-dfcd57071fbf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'build_vocabulary' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1689445642.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m vocab = build_vocab_from_iterator(\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mbuild_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mspecials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<PAD>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"<UNK>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'build_vocabulary' is not defined"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def tokenizer_es(text: str):\n",
        "    return re.findall(r\"\\b[\\w谩茅铆贸煤眉帽]+\\b\", str(text).lower())\n",
        "\n",
        "def normalize(text):\n",
        "    text = re.sub(r\"http\\S+\",\"<URL>\", text)\n",
        "    text = re.sub(r\"@\\w+\",\"<USER>\", text)\n",
        "    text = re.sub(r\"#(\\w+)\",\"\\\\1\", text)     # quita # pero deja la palabra\n",
        "    return text\n",
        "\n",
        "def tokenizer_es_norm(t):\n",
        "    return tokenizer_es(normalize(t))\n",
        "\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def generate_tokens(example: iter):\n",
        "    for text, _ in example:\n",
        "        yield tokenizer_es_norm(text)\n",
        "\n",
        "\n",
        "\n",
        "def build_vocab(etext, min_freq=1):\n",
        "    vocab = build_vocab_from_iterator(\n",
        "        generate_tokens(text),\n",
        "        min_freq=min_freq,\n",
        "        specials=[\"<PAD>\", \"<UNK>\"]   # <--- a帽ade PAD primero\n",
        "    )\n",
        "    vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "    return vocab\n",
        "\n",
        "\n",
        "vocab = build_vocab_from_iterator(\n",
        "    build_vocabulary([train_dataset, test_dataset]),\n",
        "    min_freq=1,\n",
        "    specials=[\"<PAD>\",\"<UNK>\"]\n",
        ")\n",
        "pad_idx = vocab[\"<PAD>\"]\n",
        "vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "\n",
        "\n",
        "print(f\"Tama帽o del vocabulario: {len(vocab)}\")\n",
        "print(list(vocab.get_stoi().items())[:50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eePPt8FgYaBG"
      },
      "source": [
        "#### Definir la red recurrente.\n",
        "\n",
        "Recuerde que debe difirnir los hyperparametros que estime conveniente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pHnhcCyYaBG"
      },
      "outputs": [],
      "source": [
        "embed_len = 50\n",
        "hidden_dim = 50\n",
        "n_layers=1\n",
        "\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_len, hidden_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_len)\n",
        "        self.rnn = nn.GRU(embed_len, hidden_dim, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # X: (batch, seq_len) con padding = 0\n",
        "        emb = self.embedding(X)  # (batch, seq_len, embed_len)\n",
        "\n",
        "        # longitudes reales (contar tokens != 0)\n",
        "        lengths = (X != 0).sum(dim=1)\n",
        "\n",
        "        packed = torch.nn.utils.rnn.pack_padded_sequence(\n",
        "            emb, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        _, hidden = self.rnn(packed)               # hidden: (num_layers, batch, hidden_dim)\n",
        "        logits = self.linear(hidden[-1])           # (batch, num_classes)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV5imKJUYaBH"
      },
      "source": [
        "#### Funciones de entrenamiento y evaluaci贸n.\n",
        "\n",
        "Para esta parte, puede utilizar las funciones vista en el tutorial directamente. Pero es su reponsabilidad ajustarlas a su c贸digo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjgjLzWrYaBH"
      },
      "outputs": [],
      "source": [
        "def CalcValLossAndAccuracy(model, loss_fn, val_loader):\n",
        "    with torch.no_grad():\n",
        "        Y_shuffled, Y_preds, losses = [],[],[]\n",
        "        for X, Y in val_loader:\n",
        "            preds = model(X)\n",
        "            loss = loss_fn(preds, Y)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            Y_shuffled.append(Y)\n",
        "            Y_preds.append(preds.argmax(dim=-1))\n",
        "\n",
        "        Y_shuffled = torch.cat(Y_shuffled)\n",
        "        Y_preds = torch.cat(Y_preds)\n",
        "\n",
        "        print(\"Valid Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "        print(\"Valid Acc  : {:.3f}\".format(accuracy_score(Y_shuffled.detach().numpy(), Y_preds.detach().numpy())))\n",
        "\n",
        "\n",
        "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=10):\n",
        "    for i in range(1, epochs+1):\n",
        "        losses = []\n",
        "        for X, Y in tqdm(train_loader):\n",
        "            Y_preds = model(X)\n",
        "\n",
        "            loss = loss_fn(Y_preds, Y)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "        CalcValLossAndAccuracy(model, loss_fn, val_loader)\n",
        "\n",
        "def MakePredictions(model, loader):\n",
        "    Y_shuffled, Y_preds = [], []\n",
        "    for X, Y in loader:\n",
        "        preds = model(X)\n",
        "        Y_preds.append(preds)\n",
        "        Y_shuffled.append(Y)\n",
        "    gc.collect()\n",
        "    Y_preds, Y_shuffled = torch.cat(Y_preds), torch.cat(Y_shuffled)\n",
        "\n",
        "    return Y_shuffled.detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).detach().numpy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FygL76NhYaBM"
      },
      "source": [
        "##### Entrenamiento del modelo\n",
        "\n",
        "Ejecute el entrenamiento de su modelo propuesto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOkoWFZIYaBM",
        "outputId": "550498cb-815f-433e-8a95-60dbd3ad1f7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 306/306 [00:09<00:00, 32.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 1.021\n",
            "Valid Loss : 0.967\n",
            "Valid Acc  : 0.539\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 306/306 [00:09<00:00, 33.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.867\n",
            "Valid Loss : 0.892\n",
            "Valid Acc  : 0.590\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 306/306 [00:08<00:00, 34.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.730\n",
            "Valid Loss : 0.825\n",
            "Valid Acc  : 0.644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 306/306 [00:08<00:00, 34.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.592\n",
            "Valid Loss : 0.836\n",
            "Valid Acc  : 0.664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 306/306 [00:08<00:00, 34.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.470\n",
            "Valid Loss : 0.860\n",
            "Valid Acc  : 0.669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 306/306 [00:08<00:00, 34.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.357\n",
            "Valid Loss : 0.868\n",
            "Valid Acc  : 0.673\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 306/306 [00:08<00:00, 35.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.261\n",
            "Valid Loss : 0.998\n",
            "Valid Acc  : 0.675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 306/306 [00:08<00:00, 36.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.183\n",
            "Valid Loss : 1.123\n",
            "Valid Acc  : 0.672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 306/306 [00:08<00:00, 35.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.129\n",
            "Valid Loss : 1.254\n",
            "Valid Acc  : 0.674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 306/306 [00:08<00:00, 35.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.088\n",
            "Valid Loss : 1.347\n",
            "Valid Acc  : 0.677\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\n\\nembed_len = 50\\nhidden_dim1 = 50\\nhidden_dim2 = 60\\nhidden_dim3 = 75\\nn_layers=1\\n\\n\\n\\n\\n\\n\\n\\n\\nbatch_size = 32  # o el que uses\\n\\n\\nrnn_classifier = RNNClassifier(len(vocab), embed_len, hidden_dim1, len(target_classes))\\nloss_fn = nn.CrossEntropyLoss()\\noptimizer = Adam(rnn_classifier.parameters(), lr=learning_rate) \\n\\n\\n#train_loader = DataLoader(train_dataset, batch_size=1024, collate_fn=vectorize_batch, shuffle=True)\\n# test_loader  = DataLoader(test_dataset , batch_size=1024, collate_fn=vectorize_batch)\\n\\nTrainModel(rnn_classifier, loss_fn, optimizer, train_loader, test_loader, epochs)\\n'"
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "rnn_classifier = RNNClassifier(len(vocab), embed_len, hidden_dim, len(target_classes))\n",
        "\n",
        "\n",
        "train_dataset = load_df(train_df)\n",
        "test_dataset = load_df(test_df)\n",
        "\n",
        "train_dataset = to_map_style_dataset(train_dataset)\n",
        "test_dataset = to_map_style_dataset(test_dataset)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    collate_fn=vectorize_batch,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    collate_fn=vectorize_batch,\n",
        ")\n",
        "\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(rnn_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "TrainModel(rnn_classifier, loss_fn, optimizer, train_loader, test_loader, epochs)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMeg3IphYaBM"
      },
      "source": [
        "##### Evaluacion del modelo\n",
        "\n",
        "Ejecute la evaluaci贸n de su modelo, y genere un reporte de evaluaci贸n similar al de la pregunta anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kJpJ17XYaBN"
      },
      "outputs": [],
      "source": [
        "Y_actual, Y_preds = MakePredictions(rnn_classifier, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km89dqAgYaBN",
        "outputId": "9860d4ba-47c7-40a2-a135-23390fb8a297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy : 0.6827670896438804\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal       0.64      0.68      0.66       856\n",
            " incivilidad       0.75      0.72      0.74      1085\n",
            "        odio       0.61      0.59      0.60       502\n",
            "\n",
            "    accuracy                           0.68      2443\n",
            "   macro avg       0.67      0.67      0.67      2443\n",
            "weighted avg       0.68      0.68      0.68      2443\n",
            "\n",
            "\n",
            "Confusion Matrix : \n",
            "[[585 165 106]\n",
            " [213 786  86]\n",
            " [110  95 297]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Test Accuracy : {}\".format(accuracy_score(Y_actual, Y_preds)))\n",
        "print(\"\\nClassification Report : \")\n",
        "print(classification_report(Y_actual, Y_preds, target_names=target_classes))\n",
        "print(\"\\nConfusion Matrix : \")\n",
        "print(confusion_matrix(Y_actual, Y_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-ufKF1yYaBN"
      },
      "source": [
        "Finalmente, an谩lice sus resultados, 驴Porqu茅 cree que obtuvo esos resultados?, 驴Es mejor que s贸lo utilizar Word Embeddings, porque?. Justique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C79_bo6OXZbs"
      },
      "source": [
        "Se obtiene un accuracy cercano a 0,68 y un f1 macro ~0,67, ya que el modelo captura patrones generales. Sin embargo, las fronteras entre normal, incivilidad y odio son muy difusas. La matriz de confusi贸n muestra que incivilidad tiende a confundirse con las otras altenativas.\n",
        "Se considera que el rendimiento est谩 condicionado por la calidad de los datos; en este caso, pese a que se realiz贸 un preprocesamiento menor,  los datos prencente.\n",
        "\n",
        "Si solo se usara word embeddings, este ser铆a un an谩lisis de menor calidad. Frases como no es odio y es odio pueden quedar muy parecidas num茅ricamente. Por otro lado, la RNN procesa palabra a palabra, incorporando orden y negaciones.\n",
        "\n",
        "La red construida sigue usando embeddings como representaci贸n b谩sica, pero a帽ade una capa que mejora el an谩lisis que permite entender c贸mo se construye cada mensaje a lo largo del texto. Esto es especialmente importante en una tarea donde la forma de decir las cosas es tan relevantes como las palabras en s铆."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRN7N8MiYaBO"
      },
      "source": [
        "### Transformers BERT.\n",
        "\n",
        "Para esta tarea se le piden crear una representaci贸n de texto usando la arquitectura basada en transformers, BERT:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbLjOsVNYaBO"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGvAKGyr5N1w"
      },
      "source": [
        "#### Import BETO\n",
        "\n",
        "Para esto debe importar el tokenizador y el modelo BETO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDBMwa6f5QbF"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luFLA8M5UrEs"
      },
      "source": [
        "#### Ejemplo de extracci贸n de features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_-K-wyy5aW9"
      },
      "source": [
        "Luego, debe cargar los modelos pre-entrenados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYKcuPaEYpru"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased')\n",
        "model = AutoModelForMaskedLM.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased', output_hidden_states=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g15mMOJq55kG"
      },
      "source": [
        "Una vez cargado BETO, debe utilizarlo para extraer los embeddings asociados a la texto de su corpus. Se espera que usted realice lo siguiente:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3NWG0GYR8LF"
      },
      "source": [
        "Tokenizamos el texto para extraer los ids a cada palabra en el vocabulario interno de BETO, se recomienda utilizar el padding, trunctation, y max_length para considerar oraciones de diferentes tama帽os.\n",
        "\n",
        "Luego, debe verificar si cada uno de los ids extra铆dos se encuentran en la misma m谩quina donde fue cargado el modelo (CPU o GPU), se recomienda dejar todo en GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJb8bFf_72B_"
      },
      "outputs": [],
      "source": [
        "# oraci贸n\n",
        "sentence = \"Hola, que tal? me gusta mucho el curso de NLP\"\n",
        "\n",
        "# extraemos los ids de los tokens, se recomienda definir los valores de las variables:\n",
        "#  padding, truncation, max_length debido a que las secuencia de texto puede tener diferentes largos\n",
        "inputs = tokenizer(sentence, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
        "# revisamos si cada de los ids, se encuentran en la misma m谩quina que el modelo (GPU o CPU)\n",
        "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCDiXfSJSee5"
      },
      "source": [
        "Una vez, extra铆dos los ids, usted debe obtener los estados ocultos de las ultimas capas de BETO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KBILO9E9BBD"
      },
      "outputs": [],
      "source": [
        "# Extraemos la features\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# ahora `outputs` tendr谩 el atributo `hidden_states`\n",
        "hidden_states = outputs.hidden_states\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdhiI0JDSrIs"
      },
      "source": [
        "Finalmente, debe guardar los embeddings en CPU los embeddings del token [CLS] que ser谩 usados en la clasificaci贸n del an谩lisis de sentimientos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrQqo3xlR2od"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "# Seleccionamos la 煤ltima capa y obtenemos el primer token ([CLS]) para cada ejemplo\n",
        "# Estos son los embeddings que normalmente se usan para tareas de clasificaci贸n.\n",
        "  cls_embeddings = hidden_states[-1][:, 0, :].cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr2W3pKKTAlU"
      },
      "source": [
        "#### Extraer features de todo el dataset\n",
        "\n",
        "Considerando lo anterior, usted debe implementar la funci贸n `get_beto_features_in_batches` para extraer los features de BETO (los estados ocultos y los embeddings del token [CLS]).\n",
        "\n",
        "Esta funci贸n recibe dos par谩metros, el texto a vectorizar y un tama帽o de batch, debido a que es extramadamente recomendable a que procesen el texto por lotes, ya que si cargan todos el modelo se les agotar谩 la memoria RAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Gzw5TyyTuAQ"
      },
      "outputs": [],
      "source": [
        "# Funci贸n para procesar los textos en lotes y obtener las caracter铆sticas de BETO\n",
        "\n",
        "def get_beto_features_in_batches(texts, batch_size):\n",
        "\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5ZJUHbyU21y"
      },
      "source": [
        "Ahora extra铆ga los features, un punto importante es que la extracci贸n de features podr铆a tomar alrededor de una a dos horas dependiendo del tama帽o del batch que utilicen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWiTKQTSTzs6"
      },
      "outputs": [],
      "source": [
        "train_embs = get_beto_features_in_batches(..., ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcXUZb3DT0ct"
      },
      "source": [
        "#### Clasificaci贸n\n",
        "\n",
        "Una vez extra铆do los features de BETO, realice la clasificaci贸n de los embeddings obtenidos. Debe implementar dos clasificadores a su elecci贸n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCR0rSX5UGxz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIfj6Qv3UG4Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueR_c6ETUI-q"
      },
      "source": [
        "#### Reporte de evaluaci贸n\n",
        "\n",
        "Una vez realizada la clasificaci贸n, realice el reporte de clasificaci贸n y el an谩lsis de la matriz confusi贸n para ambos clasificadores.\n",
        "\n",
        "Recuerde que para hacer esto, debe extraer los features del dataset de testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oqn_koOxUcEi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k52M9248UcKr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-iBRS3dUcnE"
      },
      "source": [
        "Finalmente, que puede decir de los resultados obtenidos. 驴Se diferencia de los resultados obtenidos de la red RNN? 驴A que se debe esto? Justifique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICYphSUXVOiA"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGj9-rkxYaBO"
      },
      "source": [
        "### Large Language Model\n",
        "\n",
        "##### Zero Shot Learning\n",
        "\n",
        "Utilizando la t茅cnica de zero shot learning, utilice la API de `openai` para clasificar el texto del dataset.\n",
        "\n",
        "Adem谩s, genere el reporte de clasificaci贸n usando `scikit-learn` como en las preguntas anteriores.\n",
        "\n",
        "Recuerde solicitar al profesor auxiliar el TOKEN para hacer consultas al LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ4GNxNcWWwo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daa9ioxdWW6H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K86Zw8jDWXVl"
      },
      "source": [
        "##### Few Shot Learning\n",
        "\n",
        "Utilizando la t茅cnica de few shot learning, utilice la API de `openai` para clasificar el texto del dataset.\n",
        "\n",
        "Adem谩s, genere el reporte de clasificaci贸n usando `scikit-learn` como en las preguntas anteriores.\n",
        "\n",
        "Recuerde solicitar al profesor auxiliar el TOKEN para hacer consultas al LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFUVpPBeWcwp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qCennW2Wc13"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}