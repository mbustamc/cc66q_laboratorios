{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBWP2pnZYaAx"
      },
      "source": [
        "# Tarea 2\n",
        "\n",
        "### Cuerpo Docente\n",
        "\n",
        "- Profesores: [Andrés Abeliuk](https://aabeliuk.github.io/), [Fabián Villena](https://villena.cl/).\n",
        "- Profesor Auxiliar: Martín Paredes\n",
        "\n",
        "### Instrucciones generales\n",
        "\n",
        "- Grupos de máximo 4 personas.\n",
        "- Esta prohibido compartir las respuestas con otros grupos.\n",
        "- Indicios de copia serán penalizados con la nota mínima.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
        "- Pueden usar cualquier material del curso que estimen conveniente, si utiliza material extra debe citarlo.\n",
        "\n",
        "\n",
        "### Integrantes\n",
        "\n",
        "1. Marco Antonio Bustamante C."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmkgPGu4YaA0"
      },
      "source": [
        "## Contexto\n",
        "\n",
        "El discurso de odio es cualquier expresión que promueva o incite a la discriminación, la hostilidad o la violencia hacia una persona o grupo de personas en una relación asimétrica de poder, tal como la raza, la etnia, el género, la orientación sexual, la religión, la nacionalidad, una discapacidad u otra característica similar.\n",
        "\n",
        "En cambio, la incivilidad se refiere a cualquier comportamiento o actitud que rompe las normas de respeto, cortesía y consideración en la interacción entre personas. Esta puede manifestarse de diversas formas, tal como insultos, ataques personales, sarcasmo, desprecio, entre otras.\n",
        "\n",
        "En esta tarea tendrán a su disposición un dataset de textos con las etiquetas `odio`, `incivilidad` o `normal`. La mayor parte de los datos se encuentra en español de Chile. Con estos datos, deberán entrenar un modelo que sea capaz de predecir la etiqueta de un texto dado.\n",
        "\n",
        "El corpus para esta tarea se compone de 3 datasets:  \n",
        "- [Multilingual Resources for Offensive Language Detection de Arango et al. (2022)](https://aclanthology.org/2022.woah-1.pdf#page=136)\n",
        "- [Dataton UTFSM No To Hate (2022)](http://dataton.inf.utfsm.cl/)\n",
        "- Datos generados usando la [API de GPT3 (modelo DaVinci 03)](https://platform.openai.com/docs/models/gpt-3).\n",
        "\n",
        "Agradecimientos a los autores por compartir los datos y a David Miranda, Fabián Diaz, Santiago Maass y Jorge Ortiz por revisar y reetiquetar los datos en el contexto del curso \"Taller de Desarrollo de Proyectos de IA\" (CC6409), Departamento de Ciencias de la Computación, Universidad de Chile.\n",
        "\n",
        "Los datos solo pueden ser usados con fines de investigación y docencia. Está prohibida la difusión externa.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_80t9I-qYaA2"
      },
      "source": [
        "## Tarea a resolver\n",
        "\n",
        "Para esta tarea 2, buscaremos desarrollar un *benchmark* sobre una tarea de clasificación de NLP. Un benchmark es básicamente utilizar diferentes técnicas para resolver una misma tarea específica, en este caso seguiremos buscando alternativas para resolver el problema de clasificación de la tarea 1. Particularmente, se le pide:\n",
        "\n",
        "- Implementar una arquitectura en RNN utilizando PyTorch.\n",
        "- Utilizar transformers para revolver el problema de clasificación, en especifico utilizar BETO.\n",
        "- Utilizar algún LLM utilizando Zero y Few short learning para resolver el problema de clasificación.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FMq5cAHYaA2"
      },
      "source": [
        "### Cargar el dataset\n",
        "\n",
        "\n",
        "En esta sección, cargaremos el dataset desde el repositorio del módulo. Para ello ejecute las siguientes líneas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "xuRRonUXYaA3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDl3c9BKYaA5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "QZMwxb4zYaA6"
      },
      "outputs": [],
      "source": [
        "# Dataset.\n",
        "dataset_df = pd.read_csv(\"https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/new/assignment_1/train/train.tsv\", sep=\"\\t\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nmaG5k2YaA6"
      },
      "source": [
        "### Analizar los datos\n",
        "\n",
        "En esta sección analizaremos el balance de los datos. Para ello se imprime la cantidad de tweets de cada dataset agrupados por la intensidad de sentimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "pDsF7qXUYaA8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>texto</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7077</th>\n",
              "      <td>4178</td>\n",
              "      <td>@user Muchas personas q han pedido el cierre d...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11692</th>\n",
              "      <td>9745</td>\n",
              "      <td>Bueno gente, si quieren votar por un tipo que ...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2089</th>\n",
              "      <td>9093</td>\n",
              "      <td>Bueno, me bloqueo el culiao. Pero aún tengo su...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7210</th>\n",
              "      <td>5143</td>\n",
              "      <td>J. A. Kast califica de “dictadura sanitaria” n...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4258</th>\n",
              "      <td>2179</td>\n",
              "      <td>@user Wnes imbeciles, como si fuera linda la w...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                              texto        clase\n",
              "7077   4178  @user Muchas personas q han pedido el cierre d...  incivilidad\n",
              "11692  9745  Bueno gente, si quieren votar por un tipo que ...  incivilidad\n",
              "2089   9093  Bueno, me bloqueo el culiao. Pero aún tengo su...  incivilidad\n",
              "7210   5143  J. A. Kast califica de “dictadura sanitaria” n...       normal\n",
              "4258   2179  @user Wnes imbeciles, como si fuera linda la w...  incivilidad"
            ]
          },
          "execution_count": 199,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "BbtCh-wrYaA9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "clase\n",
              "incivilidad    5424\n",
              "normal         4280\n",
              "odio           2510\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_df[\"clase\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "9MuLDqCr4ufP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['normal', 'incivilidad', 'odio']"
            ]
          },
          "execution_count": 201,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_classes = list(dataset_df['clase'].unique())\n",
        "target_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgIGp4p0YaA-"
      },
      "source": [
        "### Instalar librerias\n",
        "\n",
        "Puede usar esta celda para instalar las librerías que estime necesario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "3F-Dyck6YaA_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df7poQdIYaBA"
      },
      "source": [
        "### Importar librerías\n",
        "\n",
        "En esta sección, importamos la liberías necesarias para el correcto desarrollo de esta tarea. Puede utilizar otras librerías que no se en encuentran aquí, pero debe citar su fuente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "ozNxw2TD9rVX"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "35088.19s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 2.3.0+cpu\n",
            "Uninstalling torch-2.3.0+cpu:\n",
            "  Successfully uninstalled torch-2.3.0+cpu\n",
            "\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "35095.08s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Collecting torch==2.3.0\n",
            "  Using cached https://download.pytorch.org/whl/cpu/torch-2.3.0%2Bcpu-cp311-cp311-linux_x86_64.whl (190.4 MB)\n",
            "Requirement already satisfied: filelock in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from torch==2.3.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from torch==2.3.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from torch==2.3.0) (1.14.0)\n",
            "Requirement already satisfied: networkx in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from torch==2.3.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from torch==2.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from torch==2.3.0) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from jinja2->torch==2.3.0) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-2.3.0+cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "35118.32s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: scipy 1.11.4\n",
            "Uninstalling scipy-1.11.4:\n",
            "  Successfully uninstalled scipy-1.11.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "35125.10s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.11.4\n",
            "  Using cached scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from scipy==1.11.4) (1.26.4)\n",
            "Using cached scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "Installing collected packages: scipy\n",
            "Successfully installed scipy-1.11.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "35136.65s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (0.18.0)\n",
            "Requirement already satisfied: tqdm in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from torchtext) (2.32.5)\n",
            "Requirement already satisfied: torch>=2.3.0 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from torchtext) (2.3.0+cpu)\n",
            "Requirement already satisfied: numpy in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from torchtext) (1.26.4)\n",
            "Requirement already satisfied: filelock in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from torch>=2.3.0->torchtext) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from torch>=2.3.0->torchtext) (4.15.0)\n",
            "Requirement already satisfied: sympy in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from torch>=2.3.0->torchtext) (1.14.0)\n",
            "Requirement already satisfied: networkx in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from torch>=2.3.0->torchtext) (3.5)\n",
            "Requirement already satisfied: jinja2 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from torch>=2.3.0->torchtext) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from torch>=2.3.0->torchtext) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from requests->torchtext) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from requests->torchtext) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from requests->torchtext) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from requests->torchtext) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from sympy->torch>=2.3.0->torchtext) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "35143.18s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-plot in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (0.3.7)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from scikit-plot) (3.10.7)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from scikit-plot) (1.7.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from scikit-plot) (1.11.4)\n",
            "Requirement already satisfied: joblib>=0.10 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from scikit-plot) (1.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from matplotlib>=1.4.0->scikit-plot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from matplotlib>=1.4.0->scikit-plot) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from matplotlib>=1.4.0->scikit-plot) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from matplotlib>=1.4.0->scikit-plot) (12.0.0)\n",
            "Requirement already satisfied: pyparsing>=3 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from matplotlib>=1.4.0->scikit-plot) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from matplotlib>=1.4.0->scikit-plot) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.17.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from scikit-learn>=0.18->scikit-plot) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y torch torchvision torchaudio\n",
        "\n",
        "!pip install torch==2.3.0 --index-url https://download.pytorch.org/whl/cpu\n",
        "!pip uninstall -y scipy\n",
        "!pip install scipy==1.11.4\n",
        "!pip install torchtext\n",
        "!pip install scikit-plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "MUMOdsGfYaBA"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "from nltk import word_tokenize\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# importe aquí sus clasificadores\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# word2vec\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "\n",
        "# Pytorch imports\n",
        "import torch\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "\n",
        "from torch.optim import Adam\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTtn4JeJYaBD"
      },
      "source": [
        "### Crear un clasificador basado en RNN\n",
        "\n",
        "En esta parte de le pide definir un clasificador utilizando `PyTorch` con alguna arquitectura en Redes Recurrentes. Para ello debe realizar todos los pasos vistos en el tutorial 5, por lo que se recomienda revisarlo. Importante, no puede replicar ningún ejemplo de los del tutorial 5, debe proponer sus propias arquitecturas. Se le recomienda leer como utilizar variaciones de la RNN, como la LSTM o GRU en `Pytorch`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98nYKQJmYaBE"
      },
      "source": [
        "Para completa esta parte deberá replicar el flujo de trabajo de como utilizar `PyTorch`. Esta esctrictamente prohibido utilizar variaciones que resuelvan directamente este problema, como `PyTorch Lightning` o `TensorFlow`. Los pasos a completar son los siguientes:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T2bU7xgYaBE"
      },
      "source": [
        "#### Cargar el dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_df(df, test_size = 0.2, seed: int = 42):\n",
        "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=seed, stratify=df['clase'])\n",
        "    return train_df, test_df\n",
        "\n",
        "\n",
        "def load_df(df):\n",
        "   for _, row in df.iterrows():\n",
        "     yield row['texto'], row['clase']\n",
        "\n",
        "\n",
        "train_df, test_df = split_df(dataset_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8Zu0U4XYaBE"
      },
      "source": [
        "#### Definir el vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "TY_Cgtx9YaBF"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def tokenizer_es(text: str):\n",
        "    return re.findall(r\"\\b[\\wáéíóúüñÁÉÍÓÚÜÑ]+\\b\", str(text).lower())\n",
        "\n",
        "import re\n",
        "def normalize(text):\n",
        "    text = re.sub(r\"http\\S+\",\"<URL>\", text)\n",
        "    text = re.sub(r\"@\\w+\",\"<USER>\", text)\n",
        "    text = re.sub(r\"#(\\w+)\",\"\\\\1\", text)     # quita # pero deja la palabra\n",
        "    return text\n",
        "\n",
        "def tokenizer_es_norm(t):\n",
        "    return tokenizer_es(normalize(t))\n",
        "\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def generate_tokens(example: iter):\n",
        "    for text, _ in example:\n",
        "        yield tokenizer_es_norm(text)\n",
        "\n",
        "\n",
        "def build_vocab(example: iter, min_freq=1):\n",
        "    vocab = build_vocab_from_iterator(\n",
        "        generate_tokens(example),\n",
        "        min_freq=min_freq,\n",
        "        specials=[\"<UNK>\",]\n",
        "    )\n",
        "    vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "    return vocab\n",
        "\n",
        "train_data = load_df(train_df)\n",
        "vocab = build_vocab(train_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QAgIca9YaBF"
      },
      "source": [
        "#### Cargar el `DataLoader`\n",
        "\n",
        "Recuerde que podría necesitar una función intermedia para procesar cada batch durante el entrenamiento, pero no es obligatorio hacerlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "RJgaVhG2YaBF"
      },
      "outputs": [],
      "source": [
        "train_dataset = load_df(train_df)\n",
        "test_dataset = load_df(test_df)\n",
        "train_dataset, test_dataset  = to_map_style_dataset(train_dataset), to_map_style_dataset(test_dataset)\n",
        "\n",
        "max_words = 25\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_WORDS = 50\n",
        "PAD_ID = vocab[\"<PAD>\"]\n",
        "label_list = target_classes\n",
        "label2idx = {lbl: i for i, lbl in enumerate(label_list)}\n",
        "\n",
        "'''def vectorize_batch(batch):\n",
        "    # batch: lista de (texto, etiqueta)\n",
        "    X_texts, Y_labels = zip(*batch)                     # <-- orden correcto\n",
        "\n",
        "    # 1) tokenizar\n",
        "    tokenized = [tokenizer_es_norm(t) for t in X_texts]      # lista[list[str]]\n",
        "\n",
        "    # 2) tokens -> ids con torchtext\n",
        "    ids = [vocab.lookup_indices(toks) for toks in tokenized]  # lista[list[int]]\n",
        "\n",
        "    # 3) padding / truncado\n",
        "    seq_len = min(MAX_WORDS, max(len(s) for s in ids)) if ids else MAX_WORDS\n",
        "    padded = [\n",
        "        (s[:seq_len] + [PAD_ID] * (seq_len - len(s))) if len(s) < seq_len else s[:seq_len]\n",
        "        for s in ids\n",
        "    ]\n",
        "\n",
        "    # 4) tensores (Embedding espera long)\n",
        "    X = torch.tensor(padded, dtype=torch.long)\n",
        "\n",
        "    # 5) etiquetas string -> id (no restes 1)\n",
        "    y = torch.tensor([label2idx[lbl] for lbl in Y_labels], dtype=torch.long)\n",
        "\n",
        "    return X, y'''\n",
        "\n",
        "\n",
        "'''def vectorize_batch(batch):\n",
        "    Y, X = list(zip(*batch))\n",
        "    X = [vocab(tokenizer(text)) for text in X]\n",
        "    X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] ## Bringing all samples to max_words length.\n",
        "\n",
        "    return torch.tensor(X, dtype=torch.int32), torch.tensor(Y) - 1 ## We have deducted 1 from target names to get them in range [0,1,2,3] from [1,2,3,4]'''\n",
        "\n",
        "\n",
        "\n",
        "MAX_WORDS = 100\n",
        "PAD_ID = vocab[\"<PAD>\"]\n",
        "\n",
        "def vectorize_batch(batch):\n",
        "    X_texts, Y_labels = zip(*batch)\n",
        "    tokenized = [tokenizer_es_norm(t) for t in X_texts]\n",
        "    ids = [vocab.lookup_indices(toks) for toks in tokenized]\n",
        "\n",
        "    lengths = torch.tensor([min(len(s), MAX_WORDS) for s in ids], dtype=torch.long)\n",
        "    T = min(MAX_WORDS, max(lengths).item())\n",
        "    padded = [(s[:T] + [PAD_ID]*(T-len(s))) if len(s)<T else s[:T] for s in ids]\n",
        "\n",
        "    X = torch.tensor(padded, dtype=torch.long)\n",
        "    y = torch.tensor([label2idx[l] for l in Y_labels], dtype=torch.long)\n",
        "    return X, y, lengths\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, collate_fn=vectorize_batch, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset , batch_size=64, collate_fn=vectorize_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eePPt8FgYaBG"
      },
      "source": [
        "#### Definir la red recurrente.\n",
        "\n",
        "Recuerde que debe difirnir los hyperparametros que estime conveniente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OJO ____ ACA NO SE DEBE COPIAR. YO LO HICE PARA PROBAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "-pHnhcCyYaBG"
      },
      "outputs": [],
      "source": [
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        pass\n",
        "    def forward(self, X_batch):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# La siguiente es la que copie!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {},
      "outputs": [],
      "source": [
        "embed_len = 50\n",
        "hidden_dim = 50\n",
        "n_layers=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=embed_len)\n",
        "        self.rnn = nn.RNN(input_size=embed_len, hidden_size=hidden_dim, num_layers=n_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, len(target_classes))\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch)\n",
        "        output, hidden = self.rnn(embeddings, torch.randn(n_layers, len(X_batch), hidden_dim))\n",
        "        return self.linear(output[:,-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size=len(vocab), emb_dim=128, hid=128, num_classes=3, pad_idx=0):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n",
        "        self.lstm = nn.LSTM(emb_dim, hid, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.fc = nn.Linear(hid*2, num_classes)\n",
        "    def forward(self, x, lengths):\n",
        "        e = self.emb(x)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(e, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        _, (h, _) = self.lstm(packed)            # h: [num_layers*2, B, H]\n",
        "        h_last = torch.cat([h[-2], h[-1]], dim=1)  # [B, 2H]\n",
        "        return self.fc(self.dropout(h_last))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {},
      "outputs": [],
      "source": [
        "embed_len = 50\n",
        "hidden_dim1 = 50\n",
        "hidden_dim2 = 60\n",
        "hidden_dim3 = 75\n",
        "n_layers=1\n",
        "\n",
        "class StackingRNNClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StackingRNNClassifier, self).__init__()\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=embed_len)\n",
        "        self.rnn1 = nn.RNN(input_size=embed_len, hidden_size=hidden_dim1, num_layers=1, batch_first=True)\n",
        "        self.rnn2 = nn.RNN(input_size=hidden_dim1, hidden_size=hidden_dim2, num_layers=1, batch_first=True)\n",
        "        self.rnn3 = nn.RNN(input_size=hidden_dim2, hidden_size=hidden_dim3, num_layers=1, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim3, len(target_classes))\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch)\n",
        "        output, hidden = self.rnn1(embeddings, torch.randn(n_layers, len(X_batch), hidden_dim1))\n",
        "        output, hidden = self.rnn2(output, torch.randn(n_layers, len(X_batch), hidden_dim2))\n",
        "        output, hidden = self.rnn3(output, torch.randn(n_layers, len(X_batch), hidden_dim3))\n",
        "        return self.linear(output[:,-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV5imKJUYaBH"
      },
      "source": [
        "#### Funciones de entrenamiento y evaluación.\n",
        "\n",
        "Para esta parte, puede utilizar las funciones vista en el tutorial directamente. Pero es su reponsabilidad ajustarlas a su código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "VjgjLzWrYaBH"
      },
      "outputs": [],
      "source": [
        "def CalcValLossAndAccuracy(model, loss_fn, val_loader):\n",
        "    with torch.no_grad():\n",
        "        Y_shuffled, Y_preds, losses = [],[],[]\n",
        "        for X, Y in val_loader:\n",
        "            preds = model(X)\n",
        "            loss = loss_fn(preds, Y)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            Y_shuffled.append(Y)\n",
        "            Y_preds.append(preds.argmax(dim=-1))\n",
        "\n",
        "        Y_shuffled = torch.cat(Y_shuffled)\n",
        "        Y_preds = torch.cat(Y_preds)\n",
        "\n",
        "        print(\"Valid Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "        print(\"Valid Acc  : {:.3f}\".format(accuracy_score(Y_shuffled.detach().numpy(), Y_preds.detach().numpy())))\n",
        "\n",
        "\n",
        "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=10):\n",
        "    for i in range(1, epochs+1):\n",
        "        losses = []\n",
        "        for X, Y in tqdm(train_loader):\n",
        "            Y_preds = model(X)\n",
        "\n",
        "            loss = loss_fn(Y_preds, Y)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "        CalcValLossAndAccuracy(model, loss_fn, val_loader)\n",
        "\n",
        "def MakePredictions(model, loader):\n",
        "    Y_shuffled, Y_preds = [], []\n",
        "    for X, Y in loader:\n",
        "        preds = model(X)\n",
        "        Y_preds.append(preds)\n",
        "        Y_shuffled.append(Y)\n",
        "    gc.collect()\n",
        "    Y_preds, Y_shuffled = torch.cat(Y_preds), torch.cat(Y_shuffled)\n",
        "\n",
        "    return Y_shuffled.detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).detach().numpy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FygL76NhYaBM"
      },
      "source": [
        "##### Entrenamiento del modelo\n",
        "\n",
        "Ejecute el entrenamiento de su modelo propuesto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "id": "VOkoWFZIYaBM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/153 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "RNNClassifier.forward() missing 1 required positional argument: 'lengths'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[256]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m rnn_classifier = RNNClassifier()\n\u001b[32m      7\u001b[39m optimizer = Adam(rnn_classifier.parameters(), lr=learning_rate)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mTrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[255]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mTrainModel\u001b[39m\u001b[34m(model, loss_fn, optimizer, train_loader, val_loader, epochs)\u001b[39m\n\u001b[32m     21\u001b[39m losses = []\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m X, Y \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     Y_preds = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     loss = loss_fn(Y_preds, Y)\n\u001b[32m     26\u001b[39m     losses.append(loss.item())\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[31mTypeError\u001b[39m: RNNClassifier.forward() missing 1 required positional argument: 'lengths'"
          ]
        }
      ],
      "source": [
        "\n",
        "epochs = 15\n",
        "learning_rate = 1e-3\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "rnn_classifier = RNNClassifier()\n",
        "optimizer = Adam(rnn_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "TrainModel(rnn_classifier, loss_fn, optimizer, train_loader, test_loader, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMeg3IphYaBM"
      },
      "source": [
        "##### Evaluacion del modelo\n",
        "\n",
        "Ejecute la evaluación de su modelo, y genere un reporte de evaluación similar al de la pregunta anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kJpJ17XYaBN"
      },
      "outputs": [],
      "source": [
        "Y_actual, Y_preds = MakePredictions(rnn_classifier, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km89dqAgYaBN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy : 0.45272206303724927\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal       0.41      0.13      0.20       856\n",
            " incivilidad       0.47      0.89      0.61      1085\n",
            "        odio       0.31      0.06      0.10       502\n",
            "\n",
            "    accuracy                           0.45      2443\n",
            "   macro avg       0.39      0.36      0.30      2443\n",
            "weighted avg       0.41      0.45      0.36      2443\n",
            "\n",
            "\n",
            "Confusion Matrix : \n",
            "[[110 705  41]\n",
            " [ 92 966  27]\n",
            " [ 67 405  30]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Test Accuracy : {}\".format(accuracy_score(Y_actual, Y_preds)))\n",
        "print(\"\\nClassification Report : \")\n",
        "print(classification_report(Y_actual, Y_preds, target_names=target_classes))\n",
        "print(\"\\nConfusion Matrix : \")\n",
        "print(confusion_matrix(Y_actual, Y_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-ufKF1yYaBN"
      },
      "source": [
        "Finalmente, análice sus resultados, ¿Porqué cree que obtuvo esos resultados?, ¿Es mejor que sólo utilizar Word Embeddings, porque?. Justique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRN7N8MiYaBO"
      },
      "source": [
        "### Transformers BERT.\n",
        "\n",
        "Para esta tarea se le piden crear una representación de texto usando la arquitectura basada en transformers, BERT:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbLjOsVNYaBO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33730.73s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from transformers) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/mbustamc/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGvAKGyr5N1w"
      },
      "source": [
        "#### Import BETO\n",
        "\n",
        "Para esto debe importar el tokenizador y el modelo BETO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDBMwa6f5QbF"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luFLA8M5UrEs"
      },
      "source": [
        "#### Ejemplo de extracción de features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_-K-wyy5aW9"
      },
      "source": [
        "Luego, debe cargar los modelos pre-entrenados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYKcuPaEYpru"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60279932d7094c7fa1140eec218df879",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/310 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72197f5111da4596bb0d9023b05e5fa1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "432ea9e8f4384fdda17303e9fcfef541",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0eb5d801f544a4188cb46ac6e0f9013",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef73bcf76e214f308c4029239d88fee5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a22af5dd5edc4d40840163d8d59a6c64",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4811eb3bce8949ea82e757fecfe03ec6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "ValueError",
          "evalue": "Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[158]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m tokenizer = AutoTokenizer.from_pretrained(\u001b[33m'\u001b[39m\u001b[33mdccuchile/bert-base-spanish-wwm-uncased\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mAutoModelForMaskedLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdccuchile/bert-base-spanish-wwm-uncased\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:5048\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   5038\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5039\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   5041\u001b[39m     (\n\u001b[32m   5042\u001b[39m         model,\n\u001b[32m   5043\u001b[39m         missing_keys,\n\u001b[32m   5044\u001b[39m         unexpected_keys,\n\u001b[32m   5045\u001b[39m         mismatched_keys,\n\u001b[32m   5046\u001b[39m         offload_index,\n\u001b[32m   5047\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m5048\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5049\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5050\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5051\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5052\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5053\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5054\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5055\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5056\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5057\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5058\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5059\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5060\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5061\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5062\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5063\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5064\u001b[39m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[32m   5065\u001b[39m model.tie_weights()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:5316\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   5313\u001b[39m     original_checkpoint_keys = \u001b[38;5;28mlist\u001b[39m(state_dict.keys())\n\u001b[32m   5314\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   5315\u001b[39m     original_checkpoint_keys = \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m-> \u001b[39m\u001b[32m5316\u001b[39m         \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmeta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m)\u001b[49m.keys()\n\u001b[32m   5317\u001b[39m     )\n\u001b[32m   5319\u001b[39m \u001b[38;5;66;03m# Check if we are in a special state, i.e. loading from a state dict coming from a different architecture\u001b[39;00m\n\u001b[32m   5320\u001b[39m prefix = model.base_model_prefix\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:508\u001b[39m, in \u001b[36mload_state_dict\u001b[39m\u001b[34m(checkpoint_file, is_quantized, map_location, weights_only)\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# Fallback to torch.load (if weights_only was explicitly False, do not check safety as this is known to be unsafe)\u001b[39;00m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m     \u001b[43mcheck_torch_load_is_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    510\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m map_location \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/diplomados/dia_2025/cc66q_lenguaje-natural/laboratorios/.venv/lib/python3.11/site-packages/transformers/utils/import_utils.py:1647\u001b[39m, in \u001b[36mcheck_torch_load_is_safe\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1645\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_torch_load_is_safe\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1646\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_greater_or_equal(\u001b[33m\"\u001b[39m\u001b[33m2.6\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1647\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1648\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mDue to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1649\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mto upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1650\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mwhen loading files with safetensors.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1651\u001b[39m             \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1652\u001b[39m         )\n",
            "\u001b[31mValueError\u001b[39m: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased')\n",
        "model = AutoModelForMaskedLM.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased', output_hidden_states=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g15mMOJq55kG"
      },
      "source": [
        "Una vez cargado BETO, debe utilizarlo para extraer los embeddings asociados a la texto de su corpus. Se espera que usted realice lo siguiente:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3NWG0GYR8LF"
      },
      "source": [
        "Tokenizamos el texto para extraer los ids a cada palabra en el vocabulario interno de BETO, se recomienda utilizar el padding, trunctation, y max_length para considerar oraciones de diferentes tamaños.\n",
        "\n",
        "Luego, debe verificar si cada uno de los ids extraídos se encuentran en la misma máquina donde fue cargado el modelo (CPU o GPU), se recomienda dejar todo en GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJb8bFf_72B_"
      },
      "outputs": [],
      "source": [
        "# oración\n",
        "sentence = \"Hola, que tal? me gusta mucho el curso de NLP\"\n",
        "\n",
        "# extraemos los ids de los tokens, se recomienda definir los valores de las variables:\n",
        "#  padding, truncation, max_length debido a que las secuencia de texto puede tener diferentes largos\n",
        "inputs = tokenizer(sentence, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
        "# revisamos si cada de los ids, se encuentran en la misma máquina que el modelo (GPU o CPU)\n",
        "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCDiXfSJSee5"
      },
      "source": [
        "Una vez, extraídos los ids, usted debe obtener los estados ocultos de las ultimas capas de BETO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KBILO9E9BBD"
      },
      "outputs": [],
      "source": [
        "# Extraemos la features\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# ahora `outputs` tendrá el atributo `hidden_states`\n",
        "hidden_states = outputs.hidden_states\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdhiI0JDSrIs"
      },
      "source": [
        "Finalmente, debe guardar los embeddings en CPU los embeddings del token [CLS] que será usados en la clasificación del análisis de sentimientos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrQqo3xlR2od"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "# Seleccionamos la última capa y obtenemos el primer token ([CLS]) para cada ejemplo\n",
        "# Estos son los embeddings que normalmente se usan para tareas de clasificación.\n",
        "  cls_embeddings = hidden_states[-1][:, 0, :].cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr2W3pKKTAlU"
      },
      "source": [
        "#### Extraer features de todo el dataset\n",
        "\n",
        "Considerando lo anterior, usted debe implementar la función `get_beto_features_in_batches` para extraer los features de BETO (los estados ocultos y los embeddings del token [CLS]).\n",
        "\n",
        "Esta función recibe dos parámetros, el texto a vectorizar y un tamaño de batch, debido a que es extramadamente recomendable a que procesen el texto por lotes, ya que si cargan todos el modelo se les agotará la memoria RAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Gzw5TyyTuAQ"
      },
      "outputs": [],
      "source": [
        "# Función para procesar los textos en lotes y obtener las características de BETO\n",
        "\n",
        "def get_beto_features_in_batches(texts, batch_size):\n",
        "\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5ZJUHbyU21y"
      },
      "source": [
        "Ahora extraíga los features, un punto importante es que la extracción de features podría tomar alrededor de una a dos horas dependiendo del tamaño del batch que utilicen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWiTKQTSTzs6"
      },
      "outputs": [],
      "source": [
        "train_embs = get_beto_features_in_batches(..., ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcXUZb3DT0ct"
      },
      "source": [
        "#### Clasificación\n",
        "\n",
        "Una vez extraído los features de BETO, realice la clasificación de los embeddings obtenidos. Debe implementar dos clasificadores a su elección."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCR0rSX5UGxz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIfj6Qv3UG4Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueR_c6ETUI-q"
      },
      "source": [
        "#### Reporte de evaluación\n",
        "\n",
        "Una vez realizada la clasificación, realice el reporte de clasificación y el análsis de la matriz confusión para ambos clasificadores.\n",
        "\n",
        "Recuerde que para hacer esto, debe extraer los features del dataset de testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oqn_koOxUcEi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k52M9248UcKr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-iBRS3dUcnE"
      },
      "source": [
        "Finalmente, que puede decir de los resultados obtenidos. ¿Se diferencia de los resultados obtenidos de la red RNN? ¿A que se debe esto? Justifique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICYphSUXVOiA"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGj9-rkxYaBO"
      },
      "source": [
        "### Large Language Model\n",
        "\n",
        "##### Zero Shot Learning\n",
        "\n",
        "Utilizando la técnica de zero shot learning, utilice la API de `openai` para clasificar el texto del dataset.\n",
        "\n",
        "Además, genere el reporte de clasificación usando `scikit-learn` como en las preguntas anteriores.\n",
        "\n",
        "Recuerde solicitar al profesor auxiliar el TOKEN para hacer consultas al LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ4GNxNcWWwo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daa9ioxdWW6H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K86Zw8jDWXVl"
      },
      "source": [
        "##### Few Shot Learning\n",
        "\n",
        "Utilizando la técnica de few shot learning, utilice la API de `openai` para clasificar el texto del dataset.\n",
        "\n",
        "Además, genere el reporte de clasificación usando `scikit-learn` como en las preguntas anteriores.\n",
        "\n",
        "Recuerde solicitar al profesor auxiliar el TOKEN para hacer consultas al LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFUVpPBeWcwp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qCennW2Wc13"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
