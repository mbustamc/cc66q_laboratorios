{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmkgPGu4YaA0"
      },
      "source": [
        "## Contexto\n",
        "\n",
        "El discurso de odio es cualquier expresi√≥n que promueva o incite a la discriminaci√≥n, la hostilidad o la violencia hacia una persona o grupo de personas en una relaci√≥n asim√©trica de poder, tal como la raza, la etnia, el g√©nero, la orientaci√≥n sexual, la religi√≥n, la nacionalidad, una discapacidad u otra caracter√≠stica similar.\n",
        "\n",
        "En cambio, la incivilidad se refiere a cualquier comportamiento o actitud que rompe las normas de respeto, cortes√≠a y consideraci√≥n en la interacci√≥n entre personas. Esta puede manifestarse de diversas formas, tal como insultos, ataques personales, sarcasmo, desprecio, entre otras.\n",
        "\n",
        "En esta tarea tendr√°n a su disposici√≥n un dataset de textos con las etiquetas `odio`, `incivilidad` o `normal`. La mayor parte de los datos se encuentra en espa√±ol de Chile. Con estos datos, deber√°n entrenar un modelo que sea capaz de predecir la etiqueta de un texto dado.\n",
        "\n",
        "El corpus para esta tarea se compone de 3 datasets:  \n",
        "- [Multilingual Resources for Offensive Language Detection de Arango et al. (2022)](https://aclanthology.org/2022.woah-1.pdf#page=136)\n",
        "- [Dataton UTFSM No To Hate (2022)](http://dataton.inf.utfsm.cl/)\n",
        "- Datos generados usando la [API de GPT3 (modelo DaVinci 03)](https://platform.openai.com/docs/models/gpt-3).\n",
        "\n",
        "Agradecimientos a los autores por compartir los datos y a David Miranda, Fabi√°n Diaz, Santiago Maass y Jorge Ortiz por revisar y reetiquetar los datos en el contexto del curso \"Taller de Desarrollo de Proyectos de IA\" (CC6409), Departamento de Ciencias de la Computaci√≥n, Universidad de Chile.\n",
        "\n",
        "Los datos solo pueden ser usados con fines de investigaci√≥n y docencia. Est√° prohibida la difusi√≥n externa.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_80t9I-qYaA2"
      },
      "source": [
        "## Tarea a resolver\n",
        "\n",
        "Para esta tarea 2, buscaremos desarrollar un *benchmark* sobre una tarea de clasificaci√≥n de NLP. Un benchmark es b√°sicamente utilizar diferentes t√©cnicas para resolver una misma tarea espec√≠fica, en este caso seguiremos buscando alternativas para resolver el problema de clasificaci√≥n de la tarea 1. Particularmente, se le pide:\n",
        "\n",
        "- Implementar una arquitectura en RNN utilizando PyTorch.\n",
        "- Utilizar transformers para revolver el problema de clasificaci√≥n, en especifico utilizar BETO.\n",
        "- Utilizar alg√∫n LLM utilizando Zero y Few short learning para resolver el problema de clasificaci√≥n.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FMq5cAHYaA2"
      },
      "source": [
        "### Cargar el dataset\n",
        "\n",
        "\n",
        "En esta secci√≥n, cargaremos el dataset desde el repositorio del m√≥dulo. Para ello ejecute las siguientes l√≠neas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "xuRRonUXYaA3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDl3c9BKYaA5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "QZMwxb4zYaA6"
      },
      "outputs": [],
      "source": [
        "# Dataset.\n",
        "dataset_df = pd.read_csv(\"https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/new/assignment_1/train/train.tsv\", sep=\"\\t\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nmaG5k2YaA6"
      },
      "source": [
        "### Analizar los datos\n",
        "\n",
        "En esta secci√≥n analizaremos el balance de los datos. Para ello se imprime la cantidad de tweets de cada dataset agrupados por la intensidad de sentimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "pDsF7qXUYaA8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "71b8f04c-cc75-455b-d052-4482be7bcfea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id                                              texto        clase\n",
              "8755    6289  @user Y porque se tapa la cara ? A verdad que ...  incivilidad\n",
              "7755   14317  @user @user Ha de estar almorzando con la pers...       normal\n",
              "1480   12703  @user Es lo que tiene estar al lado de la muje...       normal\n",
              "1036     533  ¬°Son el ejemplo perfecto de lo que no debe ser...         odio\n",
              "5660    6686  No veo ninguna mujer pidiendo justicia por la ...       normal\n",
              "6029   11611  @user @user @user mapuche de mierda como si al...         odio\n",
              "8265   11132  @user @user Ocurre desde que el mundo es mundo...         odio\n",
              "7384    5871  @user @user @user @user @user @user @user @use...  incivilidad\n",
              "5014    5108  Cinco karatecas chilenos luchar√°n por clasific...       normal\n",
              "12007   1961  @user @user @user @user Dime una parte en que ...       normal\n",
              "8756   12203  menos mal q se recibe el a√±o con ropa blanca j...       normal\n",
              "4716    8851          La media foto CTM https://t.co/s2FGD2yS2p  incivilidad\n",
              "305    12644  dios que rabia me da no poder expresar mi bail...       normal\n",
              "4839    9591  As√≠ que en Per√∫ tambi√©n eligieron a un preside...  incivilidad\n",
              "10993  12856  Para vos Hijo de puta!!!! @user https://t.co/F...  incivilidad\n",
              "7365   10070  Tiene m√°s experiencia pol√≠tica y eso me basta....       normal\n",
              "2611   11277  Basta de poner la otra mejilla no m√°s inmigran...         odio\n",
              "11050  13997  @user @user @user Van a tener privilegios sobr...         odio\n",
              "299    10573  @user Las lacras, z√°nganos y criminales. \\nQui...         odio\n",
              "8296   10962  üòÇü§£üòÇü§£üòÇü§£üòÇü§£ que weon m√°s maricon no hab√≠a visto e...         odio"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80580fde-a039-477c-bf41-bae621cfae3c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>texto</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8755</th>\n",
              "      <td>6289</td>\n",
              "      <td>@user Y porque se tapa la cara ? A verdad que ...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7755</th>\n",
              "      <td>14317</td>\n",
              "      <td>@user @user Ha de estar almorzando con la pers...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1480</th>\n",
              "      <td>12703</td>\n",
              "      <td>@user Es lo que tiene estar al lado de la muje...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1036</th>\n",
              "      <td>533</td>\n",
              "      <td>¬°Son el ejemplo perfecto de lo que no debe ser...</td>\n",
              "      <td>odio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5660</th>\n",
              "      <td>6686</td>\n",
              "      <td>No veo ninguna mujer pidiendo justicia por la ...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6029</th>\n",
              "      <td>11611</td>\n",
              "      <td>@user @user @user mapuche de mierda como si al...</td>\n",
              "      <td>odio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8265</th>\n",
              "      <td>11132</td>\n",
              "      <td>@user @user Ocurre desde que el mundo es mundo...</td>\n",
              "      <td>odio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7384</th>\n",
              "      <td>5871</td>\n",
              "      <td>@user @user @user @user @user @user @user @use...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5014</th>\n",
              "      <td>5108</td>\n",
              "      <td>Cinco karatecas chilenos luchar√°n por clasific...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12007</th>\n",
              "      <td>1961</td>\n",
              "      <td>@user @user @user @user Dime una parte en que ...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8756</th>\n",
              "      <td>12203</td>\n",
              "      <td>menos mal q se recibe el a√±o con ropa blanca j...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4716</th>\n",
              "      <td>8851</td>\n",
              "      <td>La media foto CTM https://t.co/s2FGD2yS2p</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>12644</td>\n",
              "      <td>dios que rabia me da no poder expresar mi bail...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4839</th>\n",
              "      <td>9591</td>\n",
              "      <td>As√≠ que en Per√∫ tambi√©n eligieron a un preside...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10993</th>\n",
              "      <td>12856</td>\n",
              "      <td>Para vos Hijo de puta!!!! @user https://t.co/F...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7365</th>\n",
              "      <td>10070</td>\n",
              "      <td>Tiene m√°s experiencia pol√≠tica y eso me basta....</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2611</th>\n",
              "      <td>11277</td>\n",
              "      <td>Basta de poner la otra mejilla no m√°s inmigran...</td>\n",
              "      <td>odio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11050</th>\n",
              "      <td>13997</td>\n",
              "      <td>@user @user @user Van a tener privilegios sobr...</td>\n",
              "      <td>odio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>10573</td>\n",
              "      <td>@user Las lacras, z√°nganos y criminales. \\nQui...</td>\n",
              "      <td>odio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8296</th>\n",
              "      <td>10962</td>\n",
              "      <td>üòÇü§£üòÇü§£üòÇü§£üòÇü§£ que weon m√°s maricon no hab√≠a visto e...</td>\n",
              "      <td>odio</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80580fde-a039-477c-bf41-bae621cfae3c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-80580fde-a039-477c-bf41-bae621cfae3c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-80580fde-a039-477c-bf41-bae621cfae3c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c9ea842d-3b90-4835-bcf0-d852909df3c7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9ea842d-3b90-4835-bcf0-d852909df3c7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c9ea842d-3b90-4835-bcf0-d852909df3c7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset_df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3868,\n        \"min\": 533,\n        \"max\": 14317,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          6289,\n          13997,\n          10070\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"texto\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"@user Y porque se tapa la cara ? A verdad que es mandado .....publicidad para el payaso populista .\",\n          \"@user @user @user Van a tener privilegios sobre cualquier chileno com\\u00fan porque crear\\u00e1n un sistema de justicia paralelo al sistema general eso significa tribunales y leyes especiales q estar\\u00e1n x encima de las nuestras y eso no ayuda a pueblos ind\\u00edgenas sino a terrorismo disfrazado de ind\\u00edgenismo.\",\n          \"Tiene m\\u00e1s experiencia pol\\u00edtica y eso me basta. OJO! No soy ni DC ni de derecha ! Solo que la otra chica no me convence. No tiene un plan de gob claro y por \\u00faltimo me cargan las feministas.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clase\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"incivilidad\",\n          \"normal\",\n          \"odio\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "dataset_df.sample(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BbtCh-wrYaA9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "e1a4c1d3-7f5c-40a7-bb55-40399dc767fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "clase\n",
              "incivilidad    5424\n",
              "normal         4280\n",
              "odio           2510\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clase</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>incivilidad</th>\n",
              "      <td>5424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>normal</th>\n",
              "      <td>4280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>odio</th>\n",
              "      <td>2510</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "dataset_df[\"clase\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9MuLDqCr4ufP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "405643ca-780b-47af-c17c-7086de4053db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['normal', 'incivilidad', 'odio']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "target_classes = list(dataset_df['clase'].unique())\n",
        "target_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgIGp4p0YaA-"
      },
      "source": [
        "### Instalar librerias\n",
        "\n",
        "Puede usar esta celda para instalar las librer√≠as que estime necesario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "3F-Dyck6YaA_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install gensim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df7poQdIYaBA"
      },
      "source": [
        "### Importar librer√≠as\n",
        "\n",
        "En esta secci√≥n, importamos la liber√≠as necesarias para el correcto desarrollo de esta tarea. Puede utilizar otras librer√≠as que no se en encuentran aqu√≠, pero debe citar su fuente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ozNxw2TD9rVX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e6ffb8b7-45f4-46ac-c823-864fa812e2f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.8.0+cu126\n",
            "Uninstalling torch-2.8.0+cu126:\n",
            "  Would remove:\n",
            "    /usr/local/bin/torchfrtrace\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.12/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.12/dist-packages/torch-2.8.0+cu126.dist-info/*\n",
            "    /usr/local/lib/python3.12/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.12/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? y\n",
            "Y\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/shutil.py\", line 847, in move\n",
            "    os.rename(src, real_dst)\n",
            "OSError: [Errno 18] Invalid cross-device link: '/usr/local/lib/python3.12/dist-packages/torch/' -> '/usr/local/lib/python3.12/dist-packages/~orch'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/uninstall.py\", line 106, in run\n",
            "    uninstall_pathset = req.uninstall(\n",
            "                        ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/req/req_install.py\", line 722, in uninstall\n",
            "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/req/req_uninstall.py\", line 370, in remove\n",
            "    moved.stash(path)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/req/req_uninstall.py\", line 261, in stash\n",
            "    renames(path, new_path)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/misc.py\", line 356, in renames\n",
            "    shutil.move(old, new)\n",
            "  File \"/usr/lib/python3.12/shutil.py\", line 863, in move\n",
            "    copytree(src, real_dst, copy_function=copy_function,\n",
            "  File \"/usr/lib/python3.12/shutil.py\", line 600, in copytree\n",
            "    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/shutil.py\", line 536, in _copytree\n",
            "    copytree(srcobj, dstname, symlinks, ignore, copy_function,\n",
            "  File \"/usr/lib/python3.12/shutil.py\", line 600, in copytree\n",
            "    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/shutil.py\", line 540, in _copytree\n",
            "    copy_function(srcobj, dstname)\n",
            "  File \"/usr/lib/python3.12/shutil.py\", line 475, in copy2\n",
            "    copyfile(src, dst, follow_symlinks=follow_symlinks)\n",
            "  File \"/usr/lib/python3.12/shutil.py\", line 273, in copyfile\n",
            "    _fastcopy_sendfile(fsrc, fdst)\n",
            "  File \"/usr/lib/python3.12/shutil.py\", line 150, in _fastcopy_sendfile\n",
            "    sent = os.sendfile(outfd, infd, offset, blocksize)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 216, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1527, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1684, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1700, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1762, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1028, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.12/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1280, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1160, in emit\n",
            "    msg = self.format(record)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 999, in format\n",
            "    return fmt.format(record)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 711, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 661, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 124, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 733, in __init__\n",
            "    self.stack = StackSummary._extract_from_extended_frame_gen(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 418, in _extract_from_extended_frame_gen\n",
            "    for f, (lineno, end_lineno, colno, end_colno) in frame_gen:\n",
            "                                                     ^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 355, in _walk_tb_with_full_positions\n",
            "    positions = _get_code_position(tb.tb_frame.f_code, tb.tb_lasti)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 369, in _get_code_position\n",
            "    return next(itertools.islice(positions_gen, instruction_index // 2, None))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Collecting torch==2.3.0\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.3.0%2Bcpu-cp312-cp312-linux_x86_64.whl (190.4 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m190.4/190.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (2025.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.3.0+cpu which is incompatible.\n",
            "torchvision 0.23.0+cu126 requires torch==2.8.0, but you have torch 2.3.0+cpu which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.3.0+cpu\n",
            "Found existing installation: scipy 1.16.3\n",
            "Uninstalling scipy-1.16.3:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.12/dist-packages/scipy-1.16.3.dist-info/*\n",
            "    /usr/local/lib/python3.12/dist-packages/scipy.libs/libgfortran-040039e1-0352e75f.so.5.0.0\n",
            "    /usr/local/lib/python3.12/dist-packages/scipy.libs/libgfortran-040039e1.so.5.0.0\n",
            "    /usr/local/lib/python3.12/dist-packages/scipy.libs/libquadmath-96973f99-934c22de.so.0.0.0\n",
            "    /usr/local/lib/python3.12/dist-packages/scipy.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.12/dist-packages/scipy.libs/libscipy_openblas-b75cc656.so\n",
            "    /usr/local/lib/python3.12/dist-packages/scipy/*\n",
            "Proceed (Y/n)? Y\n",
            "Y\n",
            "  Successfully uninstalled scipy-1.16.3\n",
            "Collecting scipy==1.11.4\n",
            "  Downloading scipy-1.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy<1.28.0,>=1.21.6 (from scipy==1.11.4)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m35.8/35.8 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "torchvision 0.23.0+cu126 requires torch==2.8.0, but you have torch 2.3.0+cpu which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires scipy>=1.13, but you have scipy 1.11.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires scipy>=1.13, but you have scipy 1.11.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 scipy-1.11.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "scipy"
                ]
              },
              "id": "2111ac0dae9c4c158ee25965ab722ef6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.32.4)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.3.0+cpu)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (2025.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (2025.10.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch>=2.3.0->torchtext) (1.3.0)\n",
            "Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.18.0\n",
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from scikit-plot) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.12/dist-packages (from scikit-plot) (1.6.1)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.12/dist-packages (from scikit-plot) (1.11.4)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.12/dist-packages (from scikit-plot) (1.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.9.0.post0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.17.0)\n",
            "Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip uninstall torch torchvision torchaudio\n",
        "\n",
        "!pip install torch==2.3.0 --index-url https://download.pytorch.org/whl/cpu\n",
        "!pip uninstall scipy\n",
        "!pip install scipy==1.11.4\n",
        "!pip install torchtext\n",
        "!pip install scikit-plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "MUMOdsGfYaBA"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "from nltk import word_tokenize\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# importe aqu√≠ sus clasificadores\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# word2vec\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "\n",
        "# Pytorch imports\n",
        "import torch\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "\n",
        "from torch.optim import Adam\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTtn4JeJYaBD"
      },
      "source": [
        "### Crear un clasificador basado en RNN\n",
        "\n",
        "En esta parte de le pide definir un clasificador utilizando `PyTorch` con alguna arquitectura en Redes Recurrentes. Para ello debe realizar todos los pasos vistos en el tutorial 5, por lo que se recomienda revisarlo. Importante, no puede replicar ning√∫n ejemplo de los del tutorial 5, debe proponer sus propias arquitecturas. Se le recomienda leer como utilizar variaciones de la RNN, como la LSTM o GRU en `Pytorch`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98nYKQJmYaBE"
      },
      "source": [
        "Para completa esta parte deber√° replicar el flujo de trabajo de como utilizar `PyTorch`. Esta esctrictamente prohibido utilizar variaciones que resuelvan directamente este problema, como `PyTorch Lightning` o `TensorFlow`. Los pasos a completar son los siguientes:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T2bU7xgYaBE"
      },
      "source": [
        "#### Cargar el dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "LVVjNAV4YaBE"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_df(df, test_size = 0.2, seed: int = 42):\n",
        "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=seed, stratify=df['clase'])\n",
        "    return train_df, test_df\n",
        "\n",
        "\n",
        "def load_df(df):\n",
        "   for _, row in df.iterrows():\n",
        "     yield row['texto'], row['clase']\n",
        "\n",
        "\n",
        "train_df, test_df = split_df(dataset_df)\n",
        "\n",
        "train_dataset = load_df(train_df)\n",
        "test_dataset = load_df(test_df)\n",
        "full_dataset = load_df(dataset_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8Zu0U4XYaBE"
      },
      "source": [
        "#### Definir el vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "TY_Cgtx9YaBF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ef10099-97b3-4b13-e83b-15682a600192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tama√±o del vocabulario: 28258\n",
            "[('ùóôùóúùó°ùóîùóüùóúùó≠ùóî', 28256), ('ùóòùóπ', 28255), ('ùóóùóò', 28254), ('ùóñùó®ùó•ùó¶ùó¢', 28252), ('ùêåùêöùê†ùêùùêöùê•ùêûùêßùêö', 28249), ('ùêÉùê¢ùê†ùê¢ùê≠ùêöùê•', 28248), ('ùêÅùê¢ùêõùê•ùê¢ùê®ùê≠ùêûùêúùêö', 28247), ('Î∞©ÌÉÑÏÜåÎÖÑÎã®', 28244), ('√∫tero', 28243), ('√∫salas', 28242), ('√≥pera', 28240), ('√≥leo', 28239), ('√±uke', 28238), ('√±ora', 28236), ('√±oquis', 28235), ('√±ino', 28233), ('√±ero', 28232), ('√±ato', 28231), ('√±a', 28229), ('√≠ntimas', 28228), ('√≠ntimamente', 28227), ('√©so', 28221), ('√ßal', 28217), ('√°rboles', 28216), ('√°ngulo', 28213), ('√°ngelo', 28212), ('√°ngel', 28210), ('√°mense', 28209), ('¬Ω', 28205), ('zurich', 28202), ('zurdita', 28199), ('zurdis', 28198), ('zurdaje', 28196), ('zopiza', 28188), ('zoomjakoll', 28187), ('zoo', 28184), ('zona0', 28182), ('zionista', 28180), ('zikes', 28179), ('zendal', 28176), ('zekhem', 28174), ('zarro', 28173), ('zarpes', 28172), ('zares', 28169), ('zanjas', 28165), ('zancos', 28164), ('zamorano', 28162), ('zambrano', 28161), ('zalaquett', 28160), ('zacatecas', 28159)]\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def tokenizer_es(text: str):\n",
        "    return re.findall(r\"\\b[\\w√°√©√≠√≥√∫√º√±√Å√â√ç√ì√ö√ú√ë]+\\b\", str(text).lower())\n",
        "\n",
        "def normalize(text):\n",
        "    text = re.sub(r\"http\\S+\",\"<URL>\", text)\n",
        "    text = re.sub(r\"@\\w+\",\"<USER>\", text)\n",
        "    text = re.sub(r\"#(\\w+)\",\"\\\\1\", text)     # quita # pero deja la palabra\n",
        "    return text\n",
        "\n",
        "def tokenizer_es_norm(t):\n",
        "    return tokenizer_es(normalize(t))\n",
        "\n",
        "\n",
        "def generate_tokens(dataset):\n",
        "    for text, _ in dataset:\n",
        "        yield tokenizer_es_norm(text)\n",
        "\n",
        "\n",
        "def merge_datasets(*datasets):\n",
        "    return chain(*datasets)\n",
        "\n",
        "\n",
        "# Mezclar datasets como iterador de (texto, clase)\n",
        "full_dataset = merge_datasets(\n",
        "    load_df(train_df),\n",
        "    load_df(test_df)\n",
        ")\n",
        "\n",
        "# Construir vocabulario UNA sola vez\n",
        "vocab = build_vocab_from_iterator(\n",
        "    generate_tokens(full_dataset),\n",
        "    specials=[\"<PAD>\", \"<UNK>\"],\n",
        "    min_freq=1\n",
        ")\n",
        "\n",
        "# Ajustar \"<UNK>\"\n",
        "vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "\n",
        "pad_idx = vocab[\"<PAD>\"]\n",
        "\n",
        "print(f\"Tama√±o del vocabulario: {len(vocab)}\")\n",
        "print(list(vocab.get_stoi().items())[:50])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eePPt8FgYaBG"
      },
      "source": [
        "#### Definir la red recurrente.\n",
        "\n",
        "Recuerde que debe difirnir los hyperparametros que estime conveniente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "-pHnhcCyYaBG"
      },
      "outputs": [],
      "source": [
        "embed_len = 50\n",
        "hidden_dim = 50\n",
        "n_layers=1\n",
        "\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_len, hidden_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_len)\n",
        "        self.rnn = nn.GRU(embed_len, hidden_dim, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # X: (batch, seq_len) con padding = 0\n",
        "        emb = self.embedding(X)  # (batch, seq_len, embed_len)\n",
        "\n",
        "        # longitudes reales (contar tokens != 0)\n",
        "        lengths = (X != 0).sum(dim=1)\n",
        "\n",
        "        packed = torch.nn.utils.rnn.pack_padded_sequence(\n",
        "            emb, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        _, hidden = self.rnn(packed)               # hidden: (num_layers, batch, hidden_dim)\n",
        "        logits = self.linear(hidden[-1])           # (batch, num_classes)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV5imKJUYaBH"
      },
      "source": [
        "#### Funciones de entrenamiento y evaluaci√≥n.\n",
        "\n",
        "Para esta parte, puede utilizar las funciones vista en el tutorial directamente. Pero es su reponsabilidad ajustarlas a su c√≥digo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "VjgjLzWrYaBH"
      },
      "outputs": [],
      "source": [
        "def CalcValLossAndAccuracy(model, loss_fn, val_loader):\n",
        "    with torch.no_grad():\n",
        "        Y_shuffled, Y_preds, losses = [],[],[]\n",
        "        for X, Y in val_loader:\n",
        "            preds = model(X)\n",
        "            loss = loss_fn(preds, Y)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            Y_shuffled.append(Y)\n",
        "            Y_preds.append(preds.argmax(dim=-1))\n",
        "\n",
        "        Y_shuffled = torch.cat(Y_shuffled)\n",
        "        Y_preds = torch.cat(Y_preds)\n",
        "\n",
        "        print(\"Valid Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "        print(\"Valid Acc  : {:.3f}\".format(accuracy_score(Y_shuffled.detach().numpy(), Y_preds.detach().numpy())))\n",
        "\n",
        "\n",
        "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=10):\n",
        "    for i in range(1, epochs+1):\n",
        "        losses = []\n",
        "        for X, Y in tqdm(train_loader):\n",
        "            Y_preds = model(X)\n",
        "\n",
        "            loss = loss_fn(Y_preds, Y)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "        CalcValLossAndAccuracy(model, loss_fn, val_loader)\n",
        "\n",
        "def MakePredictions(model, loader):\n",
        "    Y_shuffled, Y_preds = [], []\n",
        "    for X, Y in loader:\n",
        "        preds = model(X)\n",
        "        Y_preds.append(preds)\n",
        "        Y_shuffled.append(Y)\n",
        "    gc.collect()\n",
        "    Y_preds, Y_shuffled = torch.cat(Y_preds), torch.cat(Y_shuffled)\n",
        "\n",
        "    return Y_shuffled.detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).detach().numpy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FygL76NhYaBM"
      },
      "source": [
        "##### Entrenamiento del modelo\n",
        "\n",
        "Ejecute el entrenamiento de su modelo propuesto."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_batch(batch):\n",
        "    \"\"\"\n",
        "    batch: lista de tuplas (texto, clase)\n",
        "    \"\"\"\n",
        "    texts, labels = zip(*batch)\n",
        "\n",
        "    # Tokenizar cada texto\n",
        "    tokenized = [tokenizer_es_norm(t) for t in texts]\n",
        "\n",
        "    # Convertir tokens a IDs\n",
        "    encoded = [encode_tokens(toks, vocab) for toks in tokenized]\n",
        "\n",
        "    # Encontrar largo m√°ximo del batch\n",
        "    max_len = max(len(seq) for seq in encoded)\n",
        "\n",
        "    # Padding manual\n",
        "    padded = [\n",
        "        seq + [pad_idx] * (max_len - len(seq))\n",
        "        for seq in encoded\n",
        "    ]\n",
        "\n",
        "    X = torch.tensor(padded, dtype=torch.long)\n",
        "    Y = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    return X, Y\n"
      ],
      "metadata": {
        "id": "WP5sdHcK5mdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "VOkoWFZIYaBM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "e5b6e80e-5af5-4114-ba38-fc64245b6f69"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'vectorize_batch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4001067697.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorize_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vectorize_batch' is not defined"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "rnn_classifier = RNNClassifier(len(vocab), embed_len, hidden_dim, len(target_classes))\n",
        "\n",
        "\n",
        "train_dataset = load_df(train_df)\n",
        "test_dataset = load_df(test_df)\n",
        "\n",
        "train_dataset = to_map_style_dataset(train_dataset)\n",
        "test_dataset = to_map_style_dataset(test_dataset)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    #collate_fn=vectorize_batch,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    collate_fn=vectorize_batch,\n",
        ")\n",
        "\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(rnn_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "TrainModel(rnn_classifier, loss_fn, optimizer, train_loader, test_loader, epochs)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMeg3IphYaBM"
      },
      "source": [
        "##### Evaluacion del modelo\n",
        "\n",
        "Ejecute la evaluaci√≥n de su modelo, y genere un reporte de evaluaci√≥n similar al de la pregunta anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kJpJ17XYaBN"
      },
      "outputs": [],
      "source": [
        "Y_actual, Y_preds = MakePredictions(rnn_classifier, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km89dqAgYaBN"
      },
      "outputs": [],
      "source": [
        "print(\"Test Accuracy : {}\".format(accuracy_score(Y_actual, Y_preds)))\n",
        "print(\"\\nClassification Report : \")\n",
        "print(classification_report(Y_actual, Y_preds, target_names=target_classes))\n",
        "print(\"\\nConfusion Matrix : \")\n",
        "print(confusion_matrix(Y_actual, Y_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-ufKF1yYaBN"
      },
      "source": [
        "Finalmente, an√°lice sus resultados, ¬øPorqu√© cree que obtuvo esos resultados?, ¬øEs mejor que s√≥lo utilizar Word Embeddings, porque?. Justique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej4zcZ15q8eh"
      },
      "source": [
        "### Comentarios:\n",
        "\n",
        "El modelo obtuvo un accuracy cercano a 0,68 y un F1 macro de aproximadamente 0,67, lo que indica que es capaz de capturar patrones generales del problema. Sin embargo, la separaci√≥n entre las categor√≠as ‚Äúnormal‚Äù, ‚Äúincivilidad‚Äù y ‚Äúodio‚Äù es por defecto, difusa, especialmente en \"incivilidad\". En la matriz de confusi√≥n, esta es la clase que presenta la mayor cantidad de predicciones err√≥neas, tanto hacia ‚Äúnormal‚Äù como hacia ‚Äúodio‚Äù.\n",
        "\n",
        "El rendimiento tambi√©n est√° condicionado por la calidad de los datos. Si bien se aplic√≥ un preprocesamiento b√°sico, los datos tienen ruido propio del lenguaje de redes sociales. Estos genera dificultades para que un modelo simple pueda distinguir con claridad los matices entre las clases.\n",
        "\n",
        "En resumen, se obtuvieron resultados apropiados para un modelo basado en RNN con un dataset complejo. Se identifican los patrones de alto nivel, pero los l√≠mites entre clases similares sem√°nticamente deterioran los resultados.\n",
        "\n",
        "Si se utilizaran solo word embeddings, el desempe√±o ser√≠a a√∫n m√°s limitado. Como los embeddings no incorporan contextofrases como ‚Äúno es odio‚Äù y ‚Äúes odio‚Äù quedar√≠an muy pr√≥ximas en el espacio vectorial, a pesar de transmitir significados opuestos. En cambio, la RNN incorpora secuencia u orden de las palabras y negaciones.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRN7N8MiYaBO"
      },
      "source": [
        "### Transformers BERT.\n",
        "\n",
        "Para esta tarea se le piden crear una representaci√≥n de texto usando la arquitectura basada en transformers, BERT:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbLjOsVNYaBO"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGvAKGyr5N1w"
      },
      "source": [
        "#### Import BETO\n",
        "\n",
        "Para esto debe importar el tokenizador y el modelo BETO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDBMwa6f5QbF"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSAmXsZaq8ek"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luFLA8M5UrEs"
      },
      "source": [
        "#### Ejemplo de extracci√≥n de features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_-K-wyy5aW9"
      },
      "source": [
        "Luego, debe cargar los modelos pre-entrenados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYKcuPaEYpru"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased')\n",
        "model = AutoModelForMaskedLM.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased', output_hidden_states=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g15mMOJq55kG"
      },
      "source": [
        "Una vez cargado BETO, debe utilizarlo para extraer los embeddings asociados a la texto de su corpus. Se espera que usted realice lo siguiente:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3NWG0GYR8LF"
      },
      "source": [
        "Tokenizamos el texto para extraer los ids a cada palabra en el vocabulario interno de BETO, se recomienda utilizar el padding, trunctation, y max_length para considerar oraciones de diferentes tama√±os.\n",
        "\n",
        "Luego, debe verificar si cada uno de los ids extra√≠dos se encuentran en la misma m√°quina donde fue cargado el modelo (CPU o GPU), se recomienda dejar todo en GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGY1CX9aq8em"
      },
      "source": [
        "# NOTA : CPU vs GPU\n",
        "\n",
        "Se realiza la construcci√≥n y las pruebas sobre CPU., y se opta por estandarizar en este tipo de arquitectura, por **acceso limitado a GPU**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJb8bFf_72B_"
      },
      "outputs": [],
      "source": [
        "# oraci√≥n\n",
        "sentence = \"Hola, que tal? me gusta mucho el curso de NLP\"\n",
        "\n",
        "# extraemos los ids de los tokens, se recomienda definir los valores de las variables:\n",
        "#  padding, truncation, max_length debido a que las secuencia de texto puede tener diferentes largos\n",
        "inputs = tokenizer(sentence, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
        "# revisamos si cada de los ids, se encuentran en la misma m√°quina que el modelo (GPU o CPU)\n",
        "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCDiXfSJSee5"
      },
      "source": [
        "Una vez, extra√≠dos los ids, usted debe obtener los estados ocultos de las ultimas capas de BETO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KBILO9E9BBD"
      },
      "outputs": [],
      "source": [
        "# Extraemos la features\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# ahora `outputs` tendr√° el atributo `hidden_states`\n",
        "hidden_states = outputs.hidden_states\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdhiI0JDSrIs"
      },
      "source": [
        "Finalmente, debe guardar los embeddings en CPU los embeddings del token [CLS] que ser√° usados en la clasificaci√≥n del an√°lisis de sentimientos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrQqo3xlR2od"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "# Seleccionamos la √∫ltima capa y obtenemos el primer token ([CLS]) para cada ejemplo\n",
        "# Estos son los embeddings que normalmente se usan para tareas de clasificaci√≥n.\n",
        "  cls_embeddings = hidden_states[-1][:, 0, :].cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr2W3pKKTAlU"
      },
      "source": [
        "#### Extraer features de todo el dataset\n",
        "\n",
        "Considerando lo anterior, usted debe implementar la funci√≥n `get_beto_features_in_batches` para extraer los features de BETO (los estados ocultos y los embeddings del token [CLS]).\n",
        "\n",
        "Esta funci√≥n recibe dos par√°metros, el texto a vectorizar y un tama√±o de batch, debido a que es extramadamente recomendable a que procesen el texto por lotes, ya que si cargan todos el modelo se les agotar√° la memoria RAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Gzw5TyyTuAQ"
      },
      "outputs": [],
      "source": [
        "# Funci√≥n para procesar los textos en lotes y obtener las caracter√≠sticas de BETO\n",
        "\n",
        "def get_beto_features_in_batches(texts, batch_size=32, max_length=128):\n",
        "    all_cls_embeddings = []\n",
        "\n",
        "    # Seteo en modo evaluaci√≥n\n",
        "    model.eval()\n",
        "\n",
        "    for start in range(0, len(texts), batch_size):\n",
        "        end = start + batch_size\n",
        "        batch_texts = list(texts[start:end])\n",
        "\n",
        "        # Tokenizaci√≥n con padding/truncation\n",
        "        batch_inputs = tokenizer(\n",
        "            batch_texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Enviar a mismo dispositivo del modelo (CPU o GPU)\n",
        "        batch_inputs = {k: v.to(model.device) for k, v in batch_inputs.items()}\n",
        "\n",
        "        # Forward sin gradientes\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch_inputs)\n",
        "            hidden_states = outputs.hidden_states\n",
        "            last_hidden = hidden_states[-1]          # (batch, seq_len, hidden_size)\n",
        "            cls_batch = last_hidden[:, 0, :]         # (batch, hidden_size)\n",
        "\n",
        "        # Guardar embeddings en CPU\n",
        "        all_cls_embeddings.append(cls_batch.cpu().numpy())\n",
        "\n",
        "        # Liberar GPU un poco si corresponde\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # Concatenamos todos los batches\n",
        "    all_cls_embeddings = np.vstack(all_cls_embeddings)\n",
        "    return all_cls_embeddings\n",
        "\n",
        "ejemplos = [\"Me encanta este curso\", \"No me gusta este comentario\"]\n",
        "embs_ejemplo = get_beto_features_in_batches(ejemplos, batch_size=2)\n",
        "embs_ejemplo.shape  # (2, 768) normalmente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5ZJUHbyU21y"
      },
      "source": [
        "Ahora extra√≠ga los features, un punto importante es que la extracci√≥n de features podr√≠a tomar alrededor de una a dos horas dependiendo del tama√±o del batch que utilicen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWiTKQTSTzs6"
      },
      "outputs": [],
      "source": [
        "train_embs = get_beto_features_in_batches(..., ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcXUZb3DT0ct"
      },
      "source": [
        "#### Clasificaci√≥n\n",
        "\n",
        "Una vez extra√≠do los features de BETO, realice la clasificaci√≥n de los embeddings obtenidos. Debe implementar dos clasificadores a su elecci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCR0rSX5UGxz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIfj6Qv3UG4Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueR_c6ETUI-q"
      },
      "source": [
        "#### Reporte de evaluaci√≥n\n",
        "\n",
        "Una vez realizada la clasificaci√≥n, realice el reporte de clasificaci√≥n y el an√°lsis de la matriz confusi√≥n para ambos clasificadores.\n",
        "\n",
        "Recuerde que para hacer esto, debe extraer los features del dataset de testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oqn_koOxUcEi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k52M9248UcKr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-iBRS3dUcnE"
      },
      "source": [
        "Finalmente, que puede decir de los resultados obtenidos. ¬øSe diferencia de los resultados obtenidos de la red RNN? ¬øA que se debe esto? Justifique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICYphSUXVOiA"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGj9-rkxYaBO"
      },
      "source": [
        "### Large Language Model\n",
        "\n",
        "##### Zero Shot Learning\n",
        "\n",
        "Utilizando la t√©cnica de zero shot learning, utilice la API de `openai` para clasificar el texto del dataset.\n",
        "\n",
        "Adem√°s, genere el reporte de clasificaci√≥n usando `scikit-learn` como en las preguntas anteriores.\n",
        "\n",
        "Recuerde solicitar al profesor auxiliar el TOKEN para hacer consultas al LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ4GNxNcWWwo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daa9ioxdWW6H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K86Zw8jDWXVl"
      },
      "source": [
        "##### Few Shot Learning\n",
        "\n",
        "Utilizando la t√©cnica de few shot learning, utilice la API de `openai` para clasificar el texto del dataset.\n",
        "\n",
        "Adem√°s, genere el reporte de clasificaci√≥n usando `scikit-learn` como en las preguntas anteriores.\n",
        "\n",
        "Recuerde solicitar al profesor auxiliar el TOKEN para hacer consultas al LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFUVpPBeWcwp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qCennW2Wc13"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}