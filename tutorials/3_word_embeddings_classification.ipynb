{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvKqz5xZ5jcN"
      },
      "source": [
        "# Word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gensim\n",
        "!pip install -U \"datasets<3.0\""
      ],
      "metadata": {
        "id": "mV1_Dsfv69eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pvQ1U_-5jcP"
      },
      "outputs": [],
      "source": [
        "import datasets # Biblioteca de manejo de conjuntos de datos para procesamiento de lenguaje natural\n",
        "import re\n",
        "import gensim # Biblioteca de modelamiento de lenguaje\n",
        "import numpy as np # Biblioteca de manejo de datos vectoriales\n",
        "import sklearn.linear_model # Módulo de sklearn de modelamiento lineal\n",
        "import sklearn.decomposition # Módulo de sklearn donde está PCA\n",
        "import plotly.express as px # Biblioteca de visualización\n",
        "import urllib # Módulo de python para el manejo de consultas web"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKp7quQ_5jcR"
      },
      "source": [
        "Cargamos el conjunto de datos del curso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfY--0lT5jcS"
      },
      "outputs": [],
      "source": [
        "spanish_diagnostics = datasets.load_dataset('fvillena/spanish_diagnostics') # Cargamos las particiones de entrenamiento y prueba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GleXxtWN5jcT"
      },
      "source": [
        "Preprocesamos el corpus."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reutilizamos la función de normalización vista en labs anteriores\n",
        "def normalize(text, remove_tildes = True):\n",
        "    \"\"\"Normaliza una cadena de texto convirtiéndo todo a minúsculas, quitando los caracteres no alfabéticos y los tildes\"\"\"\n",
        "    text = text.lower() # Llevamos todo a minúscula\n",
        "    text = re.sub(r'[^A-Za-zñáéíóú]', ' ', text) # Reemplazamos los caracteres no alfabéticos por un espacio\n",
        "    if remove_tildes:\n",
        "        text = re.sub('á', 'a', text) # Reemplazamos los tildes\n",
        "        text = re.sub('é', 'e', text)\n",
        "        text = re.sub('í', 'i', text)\n",
        "        text = re.sub('ó', 'o', text)\n",
        "        text = re.sub('ú', 'u', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "HgF3YHzG7o71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y0JOux05jcT"
      },
      "outputs": [],
      "source": [
        "spanish_diagnostics_normalized = spanish_diagnostics.map(\n",
        "    lambda x: {\n",
        "        \"normalized_text\" : normalize(x[\"text\"])\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j74pxAWF5jcU"
      },
      "outputs": [],
      "source": [
        "spanish_diagnostics_normalized_tokenized = spanish_diagnostics_normalized.map(\n",
        "    lambda x: {\n",
        "        \"tokenized_text\" : x[\"normalized_text\"].split()\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubdhFvT25jcV"
      },
      "source": [
        "## Word embeddings\n",
        "\n",
        "Los word embeddings son representaciones vectoriales de palabras. A cada una de las palabras de nuestro vocabulario se les asigna un vector que la representa y estas representaciones guardan relaciones semánticas del lenguaje natural. Por ejemplo, palabras semánticamente similares tienen a estar más cerca en el espacio que palabras no tan similares entre sí.\n",
        "\n",
        "Para calcular estas representaciones utilizaremos el método Word2Vec, en su implementación de la biblioteca Gensim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUmGZcIS5jcV"
      },
      "source": [
        "Para calcular las representaciones, simplemente pasamos nuestro corpus tokenizado al objeto Word2Vec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvetX7Xc5jcW"
      },
      "outputs": [],
      "source": [
        "model = gensim.models.Word2Vec(spanish_diagnostics_normalized_tokenized[\"train\"][\"tokenized_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6PKm5p55jcW"
      },
      "source": [
        "Tenemos una representación de 100 dimensiones para cada una de las palabras del vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tm5ia6a5jcX"
      },
      "outputs": [],
      "source": [
        "model.wv.vectors.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po-wrMOl5jcY"
      },
      "source": [
        "Si extraemos el vector asociado a una palabra se observa que está constituido de números reales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8M6DL1Ds5jcY"
      },
      "outputs": [],
      "source": [
        "model.wv[\"pieza\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5g57DNy5jcZ"
      },
      "source": [
        "Una de las métricas más utilizadas para establecer distancias entre vectores de palabras es la similaridad coseno, esta métrica está por defecto utilizada cuando deseamos saber las palabras más cercanas a un palabra que consultamos. Se observa que las palabras más cercanas a la palabra consultada guardan una estrecha relación semántica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jMdzJIj5jcZ"
      },
      "source": [
        "### Similaridad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CEKFoQ75jcZ"
      },
      "outputs": [],
      "source": [
        "model.wv.most_similar(\"pieza\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCHvkVx-5jcZ"
      },
      "source": [
        "Para continuar con la verificación de la similaridad de palabras establecemos pares de palabras en donde cada vez iremos alejándolas semánticamente. También podemos concluir que nuestro modelo pudo satisfactoriamente representar estas distancias de manera correcta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4u_sdGP5jca"
      },
      "outputs": [],
      "source": [
        "pairs = [\n",
        "    ('pieza', 'diente'), # Palabras muy cercanas semánticamente\n",
        "    ('pieza', 'caries'),\n",
        "    ('pieza', 'protesis'),\n",
        "    ('pieza', 'hueso'),\n",
        "    ('pieza', 'sangre') # Palabras muy lejanas semanticamente\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpcFgEHW5jca"
      },
      "outputs": [],
      "source": [
        "for w1, w2 in pairs:\n",
        "    print('%r\\t%r\\t%.2f' % (w1, w2, model.wv.similarity(w1, w2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfF-C_Fz5jca"
      },
      "source": [
        "Una de las aplicaciones de la similaridad de palabras es la detección de palabras fuera de contexto en una lista de palabras. En este caso el modelo detectó correctamente la palabra extraña."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hGTx5K35jcb"
      },
      "outputs": [],
      "source": [
        "model.wv.doesnt_match([\"diente\",\"periodontitis\",\"cirrosis\",\"corona\",\"lengua\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPFYvO3I5jcb"
      },
      "source": [
        "### Analogía"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nwzjJno5jcb"
      },
      "source": [
        "> Analogía, significa comparación o relación entre varias cosas, razones o conceptos; comparar o relacionar dos o más seres u objetos a través de la razón; señalando características generales y particulares comunes que permiten justificar la existencia de una propiedad en uno, a partir de la existencia de dicha propiedad en los otros.\n",
        ">\n",
        ">En el aspecto lógico, permite comparar un objeto con otros, en sus semejanzas y en sus diferencias. Una analogía permite la deducción de un término desconocido a partir del análisis de la relación que se establece entre dos términos conocidos.\n",
        ">\n",
        "> Analogía - Wikipedia\n",
        "\n",
        "Tomando en cuenta esta definición podemos construir analogías como las siguientes:\n",
        "\n",
        "* *pieza* es a *caries* como *ojo* es a *catarata*\n",
        "* *bacteria* es a *antibiótico* como *virus* es a *antiviral*\n",
        "\n",
        "Si a estos cuartetos de palabras le quitamos una, podemos transformar estas analogías en preguntas de analogía y esta es una tarea en la cual los word embeddings típicamente son probados:\n",
        "\n",
        "* *pieza* es a *caries* como *ojo* es a *¿?*\n",
        "* *bacteria* es a *antibiótico* como *virus* es a *¿?*\n",
        "\n",
        "La relación vectorial que podemos construir para resolver estas pruebas es la siguiente:\n",
        "\n",
        "Siendo $w_1$, $w_2$, $w_3$, $w_4$ los vectores asociados a las 4 palabras de la analogía, se cumple que $w_2 - w_1 \t\\approx w_4 - w_3$, por lo que para resolver una prueba de analogía, la posición de la palabra incógnita $w_4$ es $w_2 - w_1 + w_3$.\n",
        "\n",
        "Aquí vemos como nuestro modelo resuelve correctamente una prueba de analogía."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tjuf8x8X5jcb"
      },
      "outputs": [],
      "source": [
        "w_1 = model.wv[\"pieza\"]\n",
        "w_2 = model.wv[\"caries\"]\n",
        "w_3 = model.wv[\"ojo\"]\n",
        "w_4 = w_2 - w_1 + w_3\n",
        "\n",
        "model.wv.similar_by_vector(w_4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdOBdcgD5jcb"
      },
      "source": [
        "También gensim implementa el método Word2Vec.most_similar() que nos ayuda a resolver en 1 línea esta operación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdsjMnP_5jcc"
      },
      "outputs": [],
      "source": [
        "model.wv.most_similar(positive=[\"caries\", \"ojo\"], negative=[\"pieza\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iphdho-K5jcc"
      },
      "source": [
        "### Visualización\n",
        "\n",
        "Para poder visualizar nuestro espacio vectorial debemos proyectar los embeddings en 2 dimensiones, para lo cual utilizaremos un método de reducción de dimensionalidad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaehEjhk5jcc"
      },
      "outputs": [],
      "source": [
        "projector = sklearn.decomposition.PCA(3)\n",
        "vectors_2d = projector.fit_transform(model.wv.vectors)[:,:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keLsAIhz5jcc"
      },
      "source": [
        "Podemos explorar en un espacio bidimensional las relaciones de cada una de nuestras palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9H7pslU85jcc"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(\n",
        "    x=vectors_2d[:,0],\n",
        "    y=vectors_2d[:,1],\n",
        "    text=model.wv.index_to_key\n",
        ")\n",
        "fig.update_traces(mode=\"markers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEsxAiwF5jcd"
      },
      "source": [
        "### Comparación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPQe0mpq5jcd"
      },
      "source": [
        "Existen word embeddings precalculados disponibles libremente en internet. Utilizaremos como embedding de dominio general el Spanish Billion Words Corpus Embeddings y compararemos el rendimiento sobre pruebas clínicas de los 2 embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ArMP9vD5jcd"
      },
      "source": [
        "Cargamos los embeddings."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L -o sbwce_slim.txt https://raw.githubusercontent.com/dccuchile/CC66Q/main/tutorials/data/sbwce_slim.txt"
      ],
      "metadata": {
        "id": "DNzNVHMrH569"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvrgtosC5jce"
      },
      "outputs": [],
      "source": [
        "sbwce = gensim.models.KeyedVectors.load_word2vec_format(\"sbwce_slim.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7L7A8l15jce"
      },
      "source": [
        "Podemos observar que si probamos este modelo sobre palabras del dominio clínico, los resultados de estas pruebas son desfavorables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdtihrT35jce"
      },
      "outputs": [],
      "source": [
        "sbwce.most_similar(\"pieza\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLJuTakf5jce"
      },
      "outputs": [],
      "source": [
        "for w1, w2 in pairs:\n",
        "    try:\n",
        "        print('%r\\t%r\\t%.2f' % (w1, w2, sbwce.similarity(w1, w2)))\n",
        "    except KeyError as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozFOE97A5jce"
      },
      "outputs": [],
      "source": [
        "sbwce.doesnt_match([\"diente\",\"periodontitis\",\"cirrosis\",\"corona\",\"lengua\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgr73UK15jck"
      },
      "source": [
        "Probamos una analogía típica utilizada para verificar el rendimiento de los modelos de dominio general."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "OKEfN-yG5jck"
      },
      "outputs": [],
      "source": [
        "sbwce.most_similar(positive=[\"mujer\", \"rey\"], negative=[\"hombre\"], topn=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mD-aqUvJ5jck"
      },
      "outputs": [],
      "source": [
        "sbwce_2d = projector.fit_transform(sbwce.vectors)[:,:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fn-y8KJh5jck"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(\n",
        "    x=sbwce_2d[:,0],\n",
        "    y=sbwce_2d[:,1],\n",
        "    text=list(sbwce.index_to_key)\n",
        ")\n",
        "fig.update_traces(mode=\"markers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgn0FQjj5jck"
      },
      "source": [
        "## Clasificación de textos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBt4_D2l5jcl"
      },
      "source": [
        "Definimos una función que nos retornará una representación de un documento desde representaciones de palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpRgkRIw5jcl"
      },
      "outputs": [],
      "source": [
        "def to_vector(tokens,model):\n",
        "    \"\"\" Receives a sentence string along with a word embedding model and\n",
        "    returns the vector representation of the sentence\"\"\"\n",
        "    vec = np.zeros(model.vectors.shape[1]) # creates an empty vector of 300 dimensions\n",
        "    for word in tokens: # iterates over the sentence\n",
        "        if word in model: # checks if the word is in the word embedding\n",
        "            vec += model[word] # adds every word embedding to the vector\n",
        "    if np.linalg.norm(vec) > 0:\n",
        "        return vec / np.linalg.norm(vec) # divides the vector by their normal\n",
        "    else:\n",
        "        return vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivpFMtI25jcl"
      },
      "source": [
        "Utilizaremos la función definida anteriormente para obtener la representación vectorial de cada uno de los ejemplos de nuestro conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXsmO_cF5jcl"
      },
      "outputs": [],
      "source": [
        "spanish_diagnostics_normalized_tokenized_vectorized = spanish_diagnostics_normalized_tokenized.map(\n",
        "    lambda x: {\n",
        "        \"vectorized_text\" : to_vector(x[\"tokenized_text\"],model.wv)\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQiHjnBp5jcl"
      },
      "source": [
        "Exploramos el espacio y verificamos que existe una separación relativamente clara entre los documentos de las distintas clases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fb5d86b"
      },
      "source": [
        "def plot_3d(x, labels):\n",
        "    \"\"\"Generates a 3D scatter plot.\"\"\"\n",
        "    fig = px.scatter_3d(\n",
        "        x=x[:, 0],\n",
        "        y=x[:, 1],\n",
        "        z=x[:, 2],\n",
        "        color=labels,\n",
        "        opacity=0.5\n",
        "    )\n",
        "    fig.update_traces(mode=\"markers\", marker={'size': 2})\n",
        "    fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58163d2e"
      },
      "source": [
        "examples_3d = projector.fit_transform(spanish_diagnostics_normalized_tokenized_vectorized[\"test\"][\"vectorized_text\"])\n",
        "labels = spanish_diagnostics_normalized_tokenized_vectorized[\"test\"].features[\"label\"].int2str(spanish_diagnostics_normalized_tokenized_vectorized[\"test\"][\"label\"])\n",
        "\n",
        "plot_3d(examples_3d , labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKTJC2Y-5jcm"
      },
      "source": [
        "Instanciamos y ajustamos un modelo de regresión logística para clasificar nuestros textos y vemos que este método tiene un rendimiento significativamente bueno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HJ89ZT45jcm"
      },
      "outputs": [],
      "source": [
        "classifier = sklearn.linear_model.LogisticRegression(solver='liblinear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89wWKEHV5jcm"
      },
      "outputs": [],
      "source": [
        "classifier.fit(\n",
        "    spanish_diagnostics_normalized_tokenized_vectorized[\"train\"][\"vectorized_text\"],\n",
        "    spanish_diagnostics_normalized_tokenized_vectorized[\"train\"][\"label\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ40WVEw5jcm"
      },
      "outputs": [],
      "source": [
        "print(sklearn.metrics.classification_report(\n",
        "    spanish_diagnostics_normalized_tokenized_vectorized[\"test\"][\"label\"],\n",
        "    classifier.predict(spanish_diagnostics_normalized_tokenized_vectorized[\"test\"][\"vectorized_text\"])\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGAEhWsb5jcm"
      },
      "source": [
        "### Comparación de Word Embeddings\n",
        "\n",
        "Realizamos el mismo proceso de vectorización pero utilizando las representaciones de dominio general y verificamos que el rendimiento es mucho menor al anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xddQkefb5jcn"
      },
      "outputs": [],
      "source": [
        "spanish_diagnostics_normalized_tokenized_vectorized_sbwce = spanish_diagnostics_normalized_tokenized.map(\n",
        "    lambda x: {\n",
        "        \"vectorized_text\" : to_vector(x[\"tokenized_text\"],sbwce)\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itwmrkbn5jcn"
      },
      "outputs": [],
      "source": [
        "examples_3d_sbwce = projector.fit_transform(spanish_diagnostics_normalized_tokenized_vectorized_sbwce[\"test\"][\"vectorized_text\"])\n",
        "labels = spanish_diagnostics_normalized_tokenized_vectorized[\"test\"].features[\"label\"].int2str(spanish_diagnostics_normalized_tokenized_vectorized[\"test\"][\"label\"])\n",
        "\n",
        "plot_3d(examples_3d_sbwce , labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j990u-It5jcn"
      },
      "outputs": [],
      "source": [
        "classifier_sbwce = sklearn.linear_model.LogisticRegression(solver='liblinear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jB7J1dAV5jcn"
      },
      "outputs": [],
      "source": [
        "classifier.fit(\n",
        "    spanish_diagnostics_normalized_tokenized_vectorized_sbwce[\"train\"][\"vectorized_text\"],\n",
        "    spanish_diagnostics_normalized_tokenized_vectorized_sbwce[\"train\"][\"label\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fwPBJS65jcn"
      },
      "outputs": [],
      "source": [
        "print(sklearn.metrics.classification_report(\n",
        "    spanish_diagnostics_normalized_tokenized_vectorized_sbwce[\"test\"][\"label\"],\n",
        "    classifier.predict(spanish_diagnostics_normalized_tokenized_vectorized_sbwce[\"test\"][\"vectorized_text\"])\n",
        "))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}